{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from __future__ import absolute_import\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import choice\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \n",
    "from sklearn.grid_search import RandomizedSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from utils.evaluation_utils import rmsle,log_pandas,inv_log_pandas\n",
    "from utils.generic_utils import pickle_out\n",
    "import utils.preprocessing_utils as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7452, 10) (7452, 1)\n",
      "(1722, 10) (1722, 1)\n",
      "(2286, 10) (2286, 1)\n"
     ]
    }
   ],
   "source": [
    "data_folder = os.path.join(\"../\",\"datasets\",\"initial_data_split\")\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_folder,\"train.csv\"))\n",
    "valid = pd.read_csv(os.path.join(data_folder,\"valid.csv\"))\n",
    "test = pd.read_csv(os.path.join(data_folder,\"test.csv\"))\n",
    "\n",
    "X_train = train.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_train = train[[\"count\"]]\n",
    "Y_train_count = train[[\"count\"]].apply(log_pandas)\n",
    "Y_train_casual = train[[\"casual\"]].apply(log_pandas)\n",
    "Y_train_registered = train[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "X_valid = valid.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_valid = valid[[\"count\"]]\n",
    "Y_valid_count = valid[[\"count\"]].apply(log_pandas)\n",
    "Y_valid_casual = valid[[\"casual\"]].apply(log_pandas)\n",
    "Y_valid_registered = valid[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "X_test = test.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_test  = test[[\"count\"]]\n",
    "Y_test_count = test[[\"count\"]].apply(log_pandas)\n",
    "Y_test_casual = test[[\"casual\"]].apply(log_pandas)\n",
    "Y_test_registered = test[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "print X_train.shape,Y_train.shape\n",
    "print X_valid.shape,Y_valid.shape\n",
    "print X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('extract_times', ExtractTimes()), ('get_variables', ExtractColumns(colnames=['weather', 'date_year', 'workingday', 'season', 'holiday', 'time_hour', 'atemp', 'humidity', 'date_weekday', 'date_month', 'windspeed'])), ('binning_atemp', BinVariable(bins=[0, 10, 20, 30, 100], colname='atemp', dr...code_one_hot_windspeed_binned', PandasOneHotEncoder(colname='windspeed_binned', drop_colname=True))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_to_bin = ['atemp','humidity','windspeed']\n",
    "bins_per_var = [[0,10,20,30,100],[0,20,40,60,120],[0,30,1000]]\n",
    "binning_params = zip(vars_to_bin,bins_per_var)\n",
    "\n",
    "binning_steps = [('binning_%s'%var,prep.BinVariable(colname = var,\n",
    "                                                    bins = b,\n",
    "                                                    drop_column = True)) for var,b in binning_params]\n",
    "\n",
    "binned_varnames = [\"%s_binned\"%var for var,b in binning_params]\n",
    "\n",
    "get_variables =['weather','date_year','workingday','season','holiday','time_hour',\n",
    "                'atemp','humidity','date_weekday','date_month','windspeed']\n",
    "encode_variables =['weather','date_year','workingday','season','holiday']\n",
    "encode_variables.extend(binned_varnames)\n",
    "\n",
    "encoding_steps = [[('encode_label_%s'%var,prep.PandasLabelEncoder(colname=var)),\\\n",
    "        ('encode_one_hot_%s'%var,prep.PandasOneHotEncoder(colname=var,\n",
    "                                                                  drop_colname=True))] for var in encode_variables]\n",
    "encoding_steps = [en_st for sublist in encoding_steps for en_st in sublist ]\n",
    "\n",
    "prep_steps = [('extract_times', prep.ExtractTimes()),\n",
    "               ('get_variables',prep.ExtractColumns(colnames = get_variables))\n",
    "             ]+\\\n",
    "               binning_steps+\\\n",
    "                encoding_steps\n",
    "\n",
    "prep_pipe = Pipeline(prep_steps)\n",
    "prep_pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr_save = prep_pipe.transform(X_train)\n",
    "X_vd_save = prep_pipe.transform(X_valid)\n",
    "X_ts_save = prep_pipe.transform(X_test)\n",
    "\n",
    "pickle_out(os.path.join(\"../\",\"datasets\",\"generated_features\",\"train_binned.pkl\"),(X_tr_save,Y_train))\n",
    "pickle_out(os.path.join(\"../\",\"datasets\",\"generated_features\",\"valid_binned.pkl\"),(X_vd_save,Y_valid))\n",
    "pickle_out(os.path.join(\"../\",\"datasets\",\"generated_features\",\"test_binned.pkl\"),(X_ts_save,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = X_train.copy()\n",
    "X_vd = X_valid.copy()\n",
    "X_tr = prep_pipe.transform(X_tr)\n",
    "X_vd = prep_pipe.transform(X_vd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-ae79fa7cc808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mselect_pipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselection_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mX_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mX_vd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_vd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/projects/bike_sharing_codilime/utils/preprocessing_utils.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y, copy)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         X[\"datetime\"] =  pd.to_datetime(X[\"datetime\"], \n\u001b[0m\u001b[0;32m    114\u001b[0m                                            format=\"%Y-%m-%d %H:%M:%S\")\n\u001b[0;32m    115\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"time_hour\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"datetime\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1997\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2004\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3290\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1947\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "selection_steps = [(\"rf_selector\",prep.RandomForestFeatureSelector(n_estimators = 500,\n",
    "                                                                   drop_rate = 1,\n",
    "                                                                   feature_threshold = 10,\n",
    "                                                                   max_error_increase = 0.02\n",
    "                                                                  ))\n",
    "                  ]\n",
    "\n",
    "select_pipe = Pipeline(selection_steps)\n",
    "\n",
    "X_tr = select_pipe.fit_transform(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "X_vd = select_pipe.transform(X_vd)\n",
    "print X_tr.shape,X_vd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('random_forest', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
      "           max_features=12, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=3, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False))])\n",
      "Best model error on valid 0.281643370371\n"
     ]
    }
   ],
   "source": [
    "classification_steps_rf = [('random_forest',RandomForestRegressor(n_estimators=500,n_jobs=3))]\n",
    "\n",
    "classification_pipe = Pipeline(classification_steps_rf)\n",
    "\n",
    "param_dist = {\"random_forest__max_depth\": [10,15,20,None],\n",
    "              \"random_forest__max_features\": sp_randint(5, 20),\n",
    "              \"random_forest__min_samples_split\": sp_randint(1, 4),\n",
    "              \"random_forest__min_samples_leaf\": sp_randint(1, 4),\n",
    "              \"random_forest__bootstrap\": [True, False]\n",
    "             }\n",
    "\n",
    "random_search = RandomizedSearchCV(classification_pipe, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=50,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "random_search.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",random_search.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(random_search.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.425439222986\n",
      "2 0.355814864039\n",
      "3 0.345535399068\n",
      "5 0.316738339043\n",
      "10 0.293629554869\n",
      "50 0.261220532839\n",
      "100 0.260434100401\n",
      "200 0.26177390232\n",
      "300 0.265106811838\n",
      "500 0.260916452728\n",
      "1000 0.261336940465\n"
     ]
    }
   ],
   "source": [
    "number_of_trees = [1,2,3,5,10,50,100,200,300,500,1000]\n",
    "\n",
    "for nr in number_of_trees:\n",
    "    rf = RandomForestRegressor(n_estimators=nr,\n",
    "            bootstrap = True,\n",
    "            max_features = 11,\n",
    "            min_samples_split = 1,\n",
    "            min_samples_leaf = 1,\n",
    "            max_depth = 15,\n",
    "            n_jobs=3\n",
    "           )\n",
    "    rf.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "    \n",
    "    Y_pred_valid_count = pd.DataFrame(rf.predict(X_vd)).apply(inv_log_pandas)\n",
    "    valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "    print nr, valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('gradient_boosting', GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
      "             max_depth=5, max_features=8, max_leaf_nodes=None,\n",
      "             min_samples_leaf=2, min_samples_split=3,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "             warm_start=False))])\n",
      "Best model error on valid 0.265854628586\n"
     ]
    }
   ],
   "source": [
    "classification_steps_gbr = [('gradient_boosting',GradientBoostingRegressor(n_estimators=500))]\n",
    "\n",
    "classification_pipe = Pipeline(classification_steps_gbr)\n",
    "\n",
    "param_dist = {\"gradient_boosting__max_depth\": [5,10,15,20,None],\n",
    "              \"gradient_boosting__max_features\": range(3,11,1)+[None],\n",
    "              \"gradient_boosting__min_samples_split\": sp_randint(1, 4),\n",
    "              \"gradient_boosting__min_samples_leaf\": sp_randint(1, 4),\n",
    "              \"gradient_boosting__warm_start\": [True, False]\n",
    "             }\n",
    "\n",
    "random_search = RandomizedSearchCV(classification_pipe, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=50,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "random_search.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",random_search.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(random_search.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_trees = [1,2,3,5,10,50,100,200,300,500,1000]\n",
    "\n",
    "for nr in number_of_trees:\n",
    "    gbr = GradientBoostingRegressor(n_estimators=nr,\n",
    "            warm_start = True,\n",
    "            max_features = 11,\n",
    "            min_samples_split = 1,\n",
    "            min_samples_leaf = 1,\n",
    "            max_depth = 15\n",
    "           )\n",
    "    gbr.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "    \n",
    "    Y_pred_valid_count = pd.DataFrame(gbr.predict(X_vd)).apply(inv_log_pandas)\n",
    "    valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "    print nr, valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_steps_best = [('random_forest',RandomForestRegressor(n_estimators=500,\n",
    "                                                                    bootstrap = True,\n",
    "                                                                    max_features = 11,\n",
    "                                                                    min_samples_split = 1,\n",
    "                                                                    min_samples_leaf = 1,\n",
    "                                                                    max_depth = 15,\n",
    "                                                                    n_jobs=3\n",
    "                                                                     ))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model valid results: 0.259172114371\n",
      "Final model test results: 0.342106285347\n"
     ]
    }
   ],
   "source": [
    "final_steps = prep_steps+classification_steps_best\n",
    "final_pipe = Pipeline(final_steps)\n",
    "\n",
    "final_pipe.fit(X_train,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "Y_pred_valid_count = pd.DataFrame(final_pipe.predict(X_valid)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                       Y_valid_count.apply(inv_log_pandas).values.ravel()\n",
    "                          )\n",
    "print \"Final model valid results:\",valid_error_count\n",
    "\n",
    "Y_pred_test_count = pd.DataFrame(final_pipe.predict(X_test)).apply(inv_log_pandas)\n",
    "test_error_count = rmsle(Y_pred_test_count.values.ravel(),\n",
    "                       Y_test_count.apply(inv_log_pandas).values.ravel()\n",
    "                          )\n",
    "print \"Final model test results:\",test_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_filepath = os.path.join(\"../\",\"models\",\"random_forest_simple_features_5_pipeline.pkl\")\n",
    "pickle_out(model_filepath,final_pipe,compresion_mode=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
