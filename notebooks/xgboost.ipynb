{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from __future__ import absolute_import\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import choice\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \n",
    "from sklearn.grid_search import RandomizedSearchCV ,GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from utils.evaluation_utils import rmsle,rmsle_on_logs,log_pandas,inv_log_pandas,rmsle_score_on_logs\n",
    "from utils.generic_utils import pickle_out,pickle_in\n",
    "import utils.preprocessing_utils as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7452, 10) (7452, 1)\n",
      "(1722, 10) (1722, 1)\n",
      "(2286, 10) (2286, 1)\n"
     ]
    }
   ],
   "source": [
    "data_folder = os.path.join(\"../\",\"datasets\",\"initial_data_split\")\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_folder,\"train.csv\"))\n",
    "valid = pd.read_csv(os.path.join(data_folder,\"valid.csv\"))\n",
    "test = pd.read_csv(os.path.join(data_folder,\"test.csv\"))\n",
    "\n",
    "X_train = train.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_train = train[[\"count\"]]\n",
    "Y_train_count = train[[\"count\"]].apply(log_pandas)\n",
    "Y_train_casual = train[[\"casual\"]].apply(log_pandas)\n",
    "Y_train_registered = train[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "X_valid = valid.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_valid = valid[[\"count\"]]\n",
    "Y_valid_count = valid[[\"count\"]].apply(log_pandas)\n",
    "Y_valid_casual = valid[[\"casual\"]].apply(log_pandas)\n",
    "Y_valid_registered = valid[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "X_test = test.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_test  = test[[\"count\"]]\n",
    "Y_test_count = test[[\"count\"]].apply(log_pandas)\n",
    "Y_test_casual = test[[\"casual\"]].apply(log_pandas)\n",
    "Y_test_registered = test[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "full_dataset = pd.concat([train,valid,test])\n",
    "full_dataset = full_dataset.sort_values(\"datetime\")\n",
    "X_full_dataset = full_dataset.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_full_dataset = full_dataset[[\"count\"]]\n",
    "\n",
    "\n",
    "print X_train.shape,Y_train.shape\n",
    "print X_valid.shape,Y_valid.shape\n",
    "print X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('extract_times', ExtractTimes()), ('get_variables', ExtractColumns(colnames=['weather', 'date_year', 'workingday', 'season', 'holiday', 'time_hour', 'atemp', 'humidity', 'date_weekday', 'date_month', 'windspeed'])), ('binning_atemp', BinVariable(bins=[0, 10, 20, 30, 100], colname='atemp', dr...code_one_hot_windspeed_binned', PandasOneHotEncoder(colname='windspeed_binned', drop_colname=True))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_to_bin = ['atemp','humidity','windspeed']\n",
    "bins_per_var = [[0,10,20,30,100],[0,20,40,60,120],[0,30,1000]]\n",
    "binning_params = zip(vars_to_bin,bins_per_var)\n",
    "\n",
    "binning_steps = [('binning_%s'%var,prep.BinVariable(colname = var,\n",
    "                                                    bins = b,\n",
    "                                                    drop_column = False)) for var,b in binning_params]\n",
    "\n",
    "binned_varnames = [\"%s_binned\"%var for var,b in binning_params]\n",
    "\n",
    "get_variables =['weather','date_year','workingday','season','holiday','time_hour',\n",
    "                'atemp','humidity','date_weekday','date_month','windspeed']\n",
    "encode_variables =['weather','date_year','workingday','season','holiday']\n",
    "encode_variables.extend(binned_varnames)\n",
    "\n",
    "encoding_steps = [[('encode_label_%s'%var,prep.PandasLabelEncoder(colname=var)),\\\n",
    "        ('encode_one_hot_%s'%var,prep.PandasOneHotEncoder(colname=var,\n",
    "                                                                  drop_colname=True))] for var in encode_variables]\n",
    "encoding_steps = [en_st for sublist in encoding_steps for en_st in sublist ]\n",
    "\n",
    "prep_steps = [('extract_times', prep.ExtractTimes()),\n",
    "               ('get_variables',prep.ExtractColumns(colnames = get_variables))\n",
    "             ]+\\\n",
    "               binning_steps+\\\n",
    "                encoding_steps\n",
    "\n",
    "prep_pipe = Pipeline(prep_steps)\n",
    "prep_pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0.2, learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=5, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=1e-05, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9))])\n",
      "Best model error on valid 0.258991017521\n"
     ]
    }
   ],
   "source": [
    "classification_steps_all_xgb = [('xgboost',XGBRegressor(n_estimators=100,\n",
    "                                                         learning_rate=0.1))]\n",
    "\n",
    "classification_pipe_all = Pipeline(classification_steps_all_xgb)\n",
    "\n",
    "param_dist_all= {\"xgboost__max_depth\": range(2,10,1),\n",
    "                 \"xgboost__min_child_weight\":range(1,8,2),\n",
    "                 \"xgboost__gamma\": [0,0.1,0.2],\n",
    "                 \"xgboost__subsample\": [i/10.0 for i in range(6,10)],\n",
    "                 \"xgboost__colsample_bytree\": [i/10.0 for i in range(6,10)],\n",
    "                 \"xgboost__reg_alpha\":[1e-5, 1e-2, 0.1, 1, 100]\n",
    "                }\n",
    "\n",
    "random_search_all = RandomizedSearchCV(classification_pipe_all, \n",
    "                                   param_distributions = param_dist_all,\n",
    "                                   scoring = make_scorer(rmsle_score_on_logs),\n",
    "                                   n_iter=3,\n",
    "                                   n_jobs=3,\n",
    "                                   cv=2)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "random_search_all.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",random_search_all.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(random_search_all.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.56063, std: 0.06138, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.2}\n",
      "mean: -0.72017, std: 0.01943, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 2, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0}\n",
      "mean: -0.56310, std: 0.05935, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 4, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.2}\n"
     ]
    }
   ],
   "source": [
    "for a in random_search_all.grid_scores_:\n",
    "    print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8))])\n",
      "Best model error on valid 0.263076420971\n"
     ]
    }
   ],
   "source": [
    "classification_steps_tree_specific_xgb = [('xgboost',XGBRegressor(n_estimators=200,\n",
    "                                                                  learning_rate=0.1,\n",
    "                                                                  gamma = 0,\n",
    "                                                                  subsample=0.8, \n",
    "                                                                  colsample_bytree=0.8,\n",
    "                                                                  scale_pos_weight=1))]\n",
    "\n",
    "classification_pipe_tree_specific = Pipeline(classification_steps_tree_specific_xgb)\n",
    "\n",
    "param_dist_tree_specific = {\"xgboost__max_depth\": [3,5,10],\n",
    "                            \"xgboost__min_child_weight\":range(1,6,2)\n",
    "                           }\n",
    "\n",
    "grid_search_tree_specific = GridSearchCV(classification_pipe_tree_specific, \n",
    "                                   param_grid = param_dist_tree_specific,\n",
    "                                   scoring = make_scorer(rmsle_score_on_logs),\n",
    "                                   n_jobs=3,\n",
    "                                   cv=10)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "grid_search_tree_specific.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",grid_search_tree_specific.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(grid_search_tree_specific.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.35144, std: 0.05440, params: {'xgboost__max_depth': 3, 'xgboost__min_child_weight': 1},\n",
       " mean: 0.35214, std: 0.05594, params: {'xgboost__max_depth': 3, 'xgboost__min_child_weight': 3},\n",
       " mean: 0.35140, std: 0.05404, params: {'xgboost__max_depth': 3, 'xgboost__min_child_weight': 5},\n",
       " mean: 0.34499, std: 0.06347, params: {'xgboost__max_depth': 5, 'xgboost__min_child_weight': 1},\n",
       " mean: 0.34500, std: 0.06571, params: {'xgboost__max_depth': 5, 'xgboost__min_child_weight': 3},\n",
       " mean: 0.35057, std: 0.07124, params: {'xgboost__max_depth': 5, 'xgboost__min_child_weight': 5},\n",
       " mean: 0.38001, std: 0.07084, params: {'xgboost__max_depth': 10, 'xgboost__min_child_weight': 1},\n",
       " mean: 0.37012, std: 0.06639, params: {'xgboost__max_depth': 10, 'xgboost__min_child_weight': 3},\n",
       " mean: 0.37849, std: 0.08033, params: {'xgboost__max_depth': 10, 'xgboost__min_child_weight': 5}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree_specific.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree_specific.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=3, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8))])\n",
      "Best model error on valid 0.270516764698\n"
     ]
    }
   ],
   "source": [
    "classification_steps_gamma_xgb = [('xgboost',XGBRegressor(n_estimators=200,\n",
    "                                                         learning_rate=0.1,\n",
    "                                                         max_depth = 5,\n",
    "                                                         min_child_weight = 3,\n",
    "                                                         subsample=0.8, \n",
    "                                                         colsample_bytree=0.8\n",
    "                                                         ))]\n",
    "\n",
    "classification_pipe_gamma = Pipeline(classification_steps_gamma_xgb)\n",
    "\n",
    "param_grid_gamma = { \"xgboost__gamma\": [0,0.1,0.2]}\n",
    "\n",
    "grid_search_gamma = GridSearchCV(classification_pipe_gamma, \n",
    "                                   param_grid=param_grid_gamma,\n",
    "                                   scoring = make_scorer(rmsle_score_on_logs),\n",
    "                                   n_jobs=3,\n",
    "                                   cv=10)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "grid_search_gamma.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",grid_search_gamma.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(grid_search_gamma.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.34500, std: 0.06571, params: {'xgboost__gamma': 0},\n",
       " mean: 0.34289, std: 0.06143, params: {'xgboost__gamma': 0.1},\n",
       " mean: 0.34358, std: 0.06095, params: {'xgboost__gamma': 0.2}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gamma.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=3, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.6))])\n",
      "Best model error on valid 0.274256770664\n"
     ]
    }
   ],
   "source": [
    "classification_steps_subsample_xgb = [('xgboost',XGBRegressor(n_estimators=200,\n",
    "                                                         learning_rate=0.1,\n",
    "                                                         gamma = 0.1,\n",
    "                                                         max_depth = 5,\n",
    "                                                         min_child_weight = 3,\n",
    "                                                             ))]\n",
    "\n",
    "classification_pipe_subsample = Pipeline(classification_steps_subsample_xgb)\n",
    "\n",
    "param_grid_subsample = { \"xgboost__subsample\": [i/10.0 for i in range(6,10)],\n",
    "                    \"xgboost__colsample_bytree\": [i/10.0 for i in range(6,10)],\n",
    "                   }\n",
    "\n",
    "grid_search_subsample = GridSearchCV(classification_pipe_gamma, \n",
    "                                   param_grid=param_grid_subsample,\n",
    "                                   scoring = make_scorer(rmsle_score_on_logs),\n",
    "                                   n_jobs=3,\n",
    "                                   cv=10)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "grid_search_subsample.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",grid_search_subsample.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(grid_search_subsample.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.34609, std: 0.06228, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__subsample': 0.6},\n",
       " mean: 0.33782, std: 0.05530, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__subsample': 0.7},\n",
       " mean: 0.33953, std: 0.06022, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__subsample': 0.8},\n",
       " mean: 0.33716, std: 0.05810, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__subsample': 0.9},\n",
       " mean: 0.34137, std: 0.05605, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__subsample': 0.6},\n",
       " mean: 0.33908, std: 0.05566, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__subsample': 0.7},\n",
       " mean: 0.34142, std: 0.05885, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__subsample': 0.8},\n",
       " mean: 0.34441, std: 0.05879, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__subsample': 0.9},\n",
       " mean: 0.34666, std: 0.06055, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__subsample': 0.6},\n",
       " mean: 0.34511, std: 0.06230, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__subsample': 0.7},\n",
       " mean: 0.34500, std: 0.06571, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__subsample': 0.8},\n",
       " mean: 0.34294, std: 0.06442, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__subsample': 0.9},\n",
       " mean: 0.34954, std: 0.06494, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__subsample': 0.6},\n",
       " mean: 0.34580, std: 0.06295, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__subsample': 0.7},\n",
       " mean: 0.34579, std: 0.06285, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__subsample': 0.8},\n",
       " mean: 0.34667, std: 0.06243, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__subsample': 0.9}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_subsample.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.6,\n",
      "       gamma=0.1, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=3, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=100, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9))])\n",
      "Best model error on valid 0.418528839212\n"
     ]
    }
   ],
   "source": [
    "classification_steps_regul_xgb = [('xgboost',XGBRegressor(n_estimators=200,\n",
    "                                                         learning_rate=0.1,\n",
    "                                                         gamma = 0.1,\n",
    "                                                         max_depth = 5,\n",
    "                                                         min_child_weight = 3,\n",
    "                                                         subsample = 0.9,\n",
    "                                                         colsample_bytree = 0.6,\n",
    "                                                             ))]\n",
    "\n",
    "classification_pipe_regul = Pipeline(classification_steps_regul_xgb)\n",
    "\n",
    "param_grid_regul = { \"xgboost__reg_alpha\":[1e-5, 1e-2, 0.1, 1, 100]}\n",
    "\n",
    "grid_search_regul = GridSearchCV(classification_pipe_regul, \n",
    "                                   param_grid=param_grid_regul,\n",
    "                                   scoring = make_scorer(rmsle_score_on_logs),\n",
    "                                   n_jobs=3,\n",
    "                                   cv=10)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "grid_search_regul.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",grid_search_regul.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(grid_search_regul.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.34230, std: 0.06397, params: {'xgboost__reg_alpha': 1e-05},\n",
       " mean: 0.34137, std: 0.06443, params: {'xgboost__reg_alpha': 0.01},\n",
       " mean: 0.33850, std: 0.05925, params: {'xgboost__reg_alpha': 0.1},\n",
       " mean: 0.33431, std: 0.05660, params: {'xgboost__reg_alpha': 1},\n",
       " mean: 0.49809, std: 0.08508, params: {'xgboost__reg_alpha': 100}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_regul.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_steps_final_xgb = [('xgboost',XGBRegressor(n_estimators=2000,\n",
    "                                                         learning_rate=0.01,\n",
    "                                                         gamma = 0.1,\n",
    "                                                         max_depth = 5,\n",
    "                                                         min_child_weight = 3,\n",
    "                                                         subsample = 0.9,\n",
    "                                                         colsample_bytree = 0.6,\n",
    "                                                         reg_alpha= 1\n",
    "                                                             ))]\n",
    "\n",
    "classification_pipe_final = Pipeline(classification_steps_final_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model valid results: 0.267706816155\n",
      "Final model test results: 0.307521689014\n"
     ]
    }
   ],
   "source": [
    "final_steps = prep_steps+classification_steps_final_xgb\n",
    "final_pipe = Pipeline(final_steps)\n",
    "\n",
    "final_pipe.fit(X_train,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "Y_pred_valid_count = pd.DataFrame(final_pipe.predict(X_valid)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                       Y_valid_count.apply(inv_log_pandas).values.ravel()\n",
    "                          )\n",
    "print \"Final model valid results:\",valid_error_count\n",
    "\n",
    "Y_pred_test_count = pd.DataFrame(final_pipe.predict(X_test)).apply(inv_log_pandas)\n",
    "test_error_count = rmsle(Y_pred_test_count.values.ravel(),\n",
    "                       Y_test_count.apply(inv_log_pandas).values.ravel()\n",
    "                          )\n",
    "print \"Final model test results:\",test_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model test results: 0.24061306528\n"
     ]
    }
   ],
   "source": [
    "final_steps = prep_steps+classification_steps_final_xgb\n",
    "final_pipe = Pipeline(final_steps)\n",
    "\n",
    "final_pipe.fit(X_full_dataset,Y_full_dataset.apply(log_pandas).values.ravel())\n",
    "\n",
    "Y_pred_test_count = pd.DataFrame(final_pipe.predict(X_full_dataset)).apply(inv_log_pandas)\n",
    "test_error_count = rmsle(Y_pred_test_count.values.ravel(),\n",
    "                       Y_full_dataset.values.ravel()\n",
    "                          )\n",
    "print \"Final model test results:\",test_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_filepath = os.path.join(\"../\",\"models\",\"xgboost_trained_on_full_pipeline.pkl\")\n",
    "pickle_out(model_filepath,final_pipe,compresion_mode=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime      count\n",
      "0  2011-01-20 00:00:00  10.912942\n",
      "1  2011-01-20 01:00:00   4.623943\n",
      "2  2011-01-20 02:00:00   2.538523\n",
      "3  2011-01-20 03:00:00   1.740253\n",
      "4  2011-01-20 04:00:00   1.739652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakubczakon/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "kaggle_folder = os.path.join(\"../\",\"datasets\",\"kaggle_sets\")\n",
    "kaggle_test = pd.read_csv(os.path.join(kaggle_folder,\"test.csv\"))\n",
    "full_pipeline = pickle_in(os.path.join(\"../\",\"models\",\"xgboost_trained_on_full_pipeline.pkl\"),\n",
    "                          compresion_mode=5)\n",
    "\n",
    "X_test = kaggle_test\n",
    "kaggle_datetime = kaggle_test[[\"datetime\"]]\n",
    "Y_kaggle = pd.DataFrame(full_pipeline.predict(X_test)).apply(inv_log_pandas)\n",
    "kaggle_datetime[\"count\"] = Y_kaggle\n",
    "kaggle_datetime.to_csv(os.path.join(\"../\",\"submissions\",\n",
    "                                    \"xgboost_trained_on_full_submission.csv\"),index=False)\n",
    "\n",
    "print kaggle_datetime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
