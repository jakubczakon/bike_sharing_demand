{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from __future__ import absolute_import\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import choice\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \n",
    "from sklearn.grid_search import RandomizedSearchCV ,GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from utils.evaluation_utils import rmsle,rmsle_on_logs,log_pandas,inv_log_pandas\n",
    "from utils.generic_utils import pickle_out,pickle_in\n",
    "import utils.preprocessing_utils as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7452, 10) (7452, 1)\n",
      "(1722, 10) (1722, 1)\n",
      "(2286, 10) (2286, 1)\n"
     ]
    }
   ],
   "source": [
    "data_folder = os.path.join(\"../\",\"datasets\",\"initial_data_split\")\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_folder,\"train.csv\"))\n",
    "valid = pd.read_csv(os.path.join(data_folder,\"valid.csv\"))\n",
    "test = pd.read_csv(os.path.join(data_folder,\"test.csv\"))\n",
    "\n",
    "X_train = train.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_train = train[[\"count\"]]\n",
    "Y_train_count = train[[\"count\"]].apply(log_pandas)\n",
    "Y_train_casual = train[[\"casual\"]].apply(log_pandas)\n",
    "Y_train_registered = train[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "X_valid = valid.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_valid = valid[[\"count\"]]\n",
    "Y_valid_count = valid[[\"count\"]].apply(log_pandas)\n",
    "Y_valid_casual = valid[[\"casual\"]].apply(log_pandas)\n",
    "Y_valid_registered = valid[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "X_test = test.drop([\"registered\",\"casual\"], axis=1)\n",
    "Y_test  = test[[\"count\"]]\n",
    "Y_test_count = test[[\"count\"]].apply(log_pandas)\n",
    "Y_test_casual = test[[\"casual\"]].apply(log_pandas)\n",
    "Y_test_registered = test[[\"registered\"]].apply(log_pandas)\n",
    "\n",
    "print X_train.shape,Y_train.shape\n",
    "print X_valid.shape,Y_valid.shape\n",
    "print X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('extract_times', ExtractTimes()), ('get_variables', ExtractColumns(colnames=['weather', 'date_year', 'workingday', 'season', 'holiday', 'time_hour', 'atemp', 'humidity', 'date_weekday', 'date_month', 'windspeed'])), ('binning_atemp', BinVariable(bins=[0, 10, 20, 30, 100], colname='atemp', dr...code_one_hot_windspeed_binned', PandasOneHotEncoder(colname='windspeed_binned', drop_colname=True))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_to_bin = ['atemp','humidity','windspeed']\n",
    "bins_per_var = [[0,10,20,30,100],[0,20,40,60,120],[0,30,1000]]\n",
    "binning_params = zip(vars_to_bin,bins_per_var)\n",
    "\n",
    "binning_steps = [('binning_%s'%var,prep.BinVariable(colname = var,\n",
    "                                                    bins = b,\n",
    "                                                    drop_column = False)) for var,b in binning_params]\n",
    "\n",
    "binned_varnames = [\"%s_binned\"%var for var,b in binning_params]\n",
    "\n",
    "get_variables =['weather','date_year','workingday','season','holiday','time_hour',\n",
    "                'atemp','humidity','date_weekday','date_month','windspeed']\n",
    "encode_variables =['weather','date_year','workingday','season','holiday']\n",
    "encode_variables.extend(binned_varnames)\n",
    "\n",
    "encoding_steps = [[('encode_label_%s'%var,prep.PandasLabelEncoder(colname=var)),\\\n",
    "        ('encode_one_hot_%s'%var,prep.PandasOneHotEncoder(colname=var,\n",
    "                                                                  drop_colname=True))] for var in encode_variables]\n",
    "encoding_steps = [en_st for sublist in encoding_steps for en_st in sublist ]\n",
    "\n",
    "prep_steps = [('extract_times', prep.ExtractTimes()),\n",
    "               ('get_variables',prep.ExtractColumns(colnames = get_variables))\n",
    "             ]+\\\n",
    "               binning_steps+\\\n",
    "                encoding_steps\n",
    "\n",
    "prep_pipe = Pipeline(prep_steps)\n",
    "prep_pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.6,\n",
      "       gamma=0.2, learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=100, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9))])\n",
      "Best model error on valid 0.53155104223\n"
     ]
    }
   ],
   "source": [
    "classification_steps_all_xgb = [('xgboost',XGBRegressor(n_estimators=200,\n",
    "                                                         learning_rate=0.1))]\n",
    "\n",
    "classification_pipe_all = Pipeline(classification_steps_all_xgb)\n",
    "\n",
    "param_dist_all= {\"xgboost__max_depth\": range(2,10,1),\n",
    "                 \"xgboost__min_child_weight\":range(1,8,2),\n",
    "                 \"xgboost__gamma\": [0,0.1,0.2],\n",
    "                 \"xgboost__subsample\": [i/10.0 for i in range(6,10)],\n",
    "                 \"xgboost__colsample_bytree\": [i/10.0 for i in range(6,10)],\n",
    "                 \"xgboost__reg_alpha\":[1e-5, 1e-2, 0.1, 1, 100]\n",
    "                }\n",
    "\n",
    "random_search_all = RandomizedSearchCV(classification_pipe_all, \n",
    "                                   param_distributions = param_dist_all,\n",
    "                                   scoring = make_scorer(rmsle_on_logs),\n",
    "                                   n_iter=100,\n",
    "                                   n_jobs=3,\n",
    "                                   cv=10)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "random_search_all.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",random_search_all.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(random_search_all.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.36822, std: 0.07278, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 0.01, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0}, mean: 0.50386, std: 0.09870, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.1}, mean: 0.55696, std: 0.08568, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0}, mean: 0.34990, std: 0.05898, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 7, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 0.1, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0}, mean: 0.46321, std: 0.04601, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 2, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 0.1, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0}, mean: 0.34203, std: 0.05685, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 7, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.2}, mean: 0.33676, std: 0.05479, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 4, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0}, mean: 0.54322, std: 0.07851, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 3, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.2}, mean: 0.34310, std: 0.06433, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 5, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.52768, std: 0.09456, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0.1}, mean: 0.34446, std: 0.05656, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 5, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0.2}, mean: 0.33621, std: 0.05759, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 5, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.2}, mean: 0.35695, std: 0.05294, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 3, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 0.01, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.1}, mean: 0.35920, std: 0.05705, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 3, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.35090, std: 0.05906, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0.2}, mean: 0.35151, std: 0.06117, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 6, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0.2}, mean: 0.34704, std: 0.05774, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 7, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0.1}, mean: 0.35037, std: 0.05553, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 0.1, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.1}, mean: 0.34238, std: 0.05070, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0}, mean: 0.46705, std: 0.05509, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 2, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 0.01, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0}, mean: 0.46118, std: 0.04854, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 2, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 0.01, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0}, mean: 0.35075, std: 0.05569, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 0.1, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0.1}, mean: 0.35023, std: 0.06945, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 5, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.1}, mean: 0.34818, std: 0.06669, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 6, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.2}, mean: 0.33932, std: 0.06004, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 5, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 0.1, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0}, mean: 0.35739, std: 0.06687, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 7, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 0.01, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.2}, mean: 0.35001, std: 0.06669, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 6, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 0.01, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0}, mean: 0.33732, std: 0.05941, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 6, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.1}, mean: 0.55211, std: 0.08090, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 3, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.1}, mean: 0.36425, std: 0.06599, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 0.1, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0.1}, mean: 0.33270, std: 0.05226, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 4, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.2}, mean: 0.50957, std: 0.09867, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 6, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.33626, std: 0.05454, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.53039, std: 0.09332, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0.2}, mean: 0.50696, std: 0.09703, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.51542, std: 0.09465, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 5, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.35291, std: 0.05624, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0.1}, mean: 0.34260, std: 0.05574, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 7, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0.2}, mean: 0.52640, std: 0.09477, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 6, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0}, mean: 0.34878, std: 0.06582, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 6, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 0.1, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.53204, std: 0.08824, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 4, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.2}, mean: 0.33952, std: 0.05985, params: {'xgboost__colsample_bytree': 0.8, 'xgboost__max_depth': 5, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.35983, std: 0.05739, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0}, mean: 0.34901, std: 0.06295, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 7, 'xgboost__min_child_weight': 3, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0}, mean: 0.35371, std: 0.06279, params: {'xgboost__colsample_bytree': 0.9, 'xgboost__max_depth': 7, 'xgboost__min_child_weight': 5, 'xgboost__reg_alpha': 0.01, 'xgboost__subsample': 0.7, 'xgboost__gamma': 0}, mean: 0.34021, std: 0.05279, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 9, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.2}, mean: 0.34155, std: 0.05358, params: {'xgboost__colsample_bytree': 0.7, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 1, 'xgboost__subsample': 0.6, 'xgboost__gamma': 0}, mean: 0.50169, std: 0.09711, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 8, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.2}, mean: 0.33457, std: 0.05411, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 5, 'xgboost__min_child_weight': 7, 'xgboost__reg_alpha': 1e-05, 'xgboost__subsample': 0.8, 'xgboost__gamma': 0.2}, mean: 0.59582, std: 0.07777, params: {'xgboost__colsample_bytree': 0.6, 'xgboost__max_depth': 2, 'xgboost__min_child_weight': 1, 'xgboost__reg_alpha': 100, 'xgboost__subsample': 0.9, 'xgboost__gamma': 0.2}]\n"
     ]
    }
   ],
   "source": [
    "print random_search_all.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1c77623c6d62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mX_vd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mgrid_search_tree_specific\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_pandas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Best Params\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_search_tree_specific\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 for train, test in cv)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    810\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    760\u001b[0m                         \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classification_steps_tree_specific_xgb = [('xgboost',XGBRegressor(n_estimators=200,\n",
    "                                                                  learning_rate=0.1,\n",
    "                                                                  gamma = 0,\n",
    "                                                                  subsample=0.8, \n",
    "                                                                  colsample_bytree=0.8,\n",
    "                                                                  scale_pos_weight=1))]\n",
    "\n",
    "classification_pipe_tree_specific = Pipeline(classification_steps_tree_specific_xgb)\n",
    "\n",
    "param_dist_tree_specific = {\"xgboost__max_depth\": range(2,10,1),\n",
    "                            \"xgboost__min_child_weight\":range(1,8,2)\n",
    "                           }\n",
    "\n",
    "grid_search_tree_specific = GridSearchCV(classification_pipe_tree_specific, \n",
    "                                   param_grid = param_dist_tree_specific,\n",
    "                                   scoring = make_scorer(rmsle_on_logs),\n",
    "                                   n_jobs=3,\n",
    "                                   cv=10)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "grid_search_tree_specific.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",grid_search_tree_specific.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(grid_search_tree_specific.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0.1, learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=3, missing=None, n_estimators=10, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8))])\n",
      "Best model error on valid 1.66012738575\n"
     ]
    }
   ],
   "source": [
    "classification_steps_gamma_xgb = [('xgboost',XGBRegressor(n_estimators=10,\n",
    "                                                         learning_rate=0.1,\n",
    "                                                         max_depth = 4,\n",
    "                                                         min_child_weight = 3,\n",
    "                                                         subsample=0.8, \n",
    "                                                         colsample_bytree=0.8,\n",
    "                                                         scale_pos_weight=1))]\n",
    "\n",
    "classification_pipe_gamma = Pipeline(classification_steps_gamma_xgb)\n",
    "\n",
    "param_grid_gamma = { \"xgboost__gamma\": [0,0.1,0.2]}\n",
    "\n",
    "grid_search_gamma = GridSearchCV(classification_pipe_gamma, \n",
    "                                   param_grid=param_grid_gamma,\n",
    "                                   scoring = make_scorer(rmsle_on_logs),\n",
    "                                   n_jobs=3,\n",
    "                                   cv=3)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "grid_search_gamma.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",grid_search_gamma.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(grid_search_gamma.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.6,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=3, missing=None, n_estimators=10, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8))])\n",
      "Best model error on valid 1.68318089282\n"
     ]
    }
   ],
   "source": [
    "classification_steps_subsample_xgb = [('xgboost',XGBRegressor(n_estimators=10,\n",
    "                                                         learning_rate=0.1,\n",
    "                                                         gamma = 0.1,\n",
    "                                                         max_depth = 4,\n",
    "                                                         min_child_weight = 3,\n",
    "                                                         scale_pos_weight=1,\n",
    "                                                             ))]\n",
    "\n",
    "classification_pipe_subsample = Pipeline(classification_steps_subsample_xgb)\n",
    "\n",
    "param_grid_subsample = { \"xgboost__subsample\": [i/10.0 for i in range(6,10)],\n",
    "                    \"xgboost__colsample_bytree\": [i/10.0 for i in range(6,10)],\n",
    "                   }\n",
    "\n",
    "grid_search_subsample = GridSearchCV(classification_pipe_gamma, \n",
    "                                   param_grid=param_grid_subsample,\n",
    "                                   scoring = make_scorer(rmsle_on_logs),\n",
    "                                   n_jobs=3,\n",
    "                                   cv=3)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "grid_search_subsample.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",grid_search_subsample.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(grid_search_subsample.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.6,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=3, missing=None, n_estimators=10, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=100, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8))])\n",
      "Best model error on valid 1.77159671304\n"
     ]
    }
   ],
   "source": [
    "classification_steps_regul_xgb = [('xgboost',XGBRegressor(n_estimators=10,\n",
    "                                                         learning_rate=0.1,\n",
    "                                                         gamma = 0,\n",
    "                                                         max_depth = 4,\n",
    "                                                         min_child_weight = 3,\n",
    "                                                         scale_pos_weight=1,\n",
    "                                                         subsample = 0.8,\n",
    "                                                         colsample_bytree = 0.6,\n",
    "                                                             ))]\n",
    "\n",
    "classification_pipe_regul = Pipeline(classification_steps_regul_xgb)\n",
    "\n",
    "param_grid_regul = { \"xgboost__reg_alpha\":[1e-5, 1e-2, 0.1, 1, 100]}\n",
    "\n",
    "grid_search_regul = GridSearchCV(classification_pipe_regul, \n",
    "                                   param_grid=param_grid_regul,\n",
    "                                   scoring = make_scorer(rmsle_on_logs),\n",
    "                                   n_jobs=3,\n",
    "                                   cv=3)\n",
    "\n",
    "X_tr = prep_pipe.transform(X_train)\n",
    "X_vd = prep_pipe.transform(X_valid)\n",
    "\n",
    "grid_search_regul.fit(X_tr,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "print \"Best Params\",grid_search_regul.best_estimator_\n",
    "Y_pred_valid_count = pd.DataFrame(grid_search_regul.predict(X_vd)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                           Y_valid_count.apply(inv_log_pandas).values.ravel())\n",
    "print \"Best model error on valid\",valid_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('xgboost', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.6,\n",
      "       gamma=0.2, learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=100, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9))])\n"
     ]
    }
   ],
   "source": [
    "print random_search_all.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_steps_final_xgb = [('xgboost',XGBRegressor(n_estimators=2000,\n",
    "                                                         learning_rate=0.01,\n",
    "#                                                          gamma = 0.2,\n",
    "#                                                          max_depth = 2,\n",
    "#                                                          min_child_weight = 1,\n",
    "#                                                          scale_pos_weight=1,\n",
    "#                                                          subsample = 0.9,\n",
    "#                                                          colsample_bytree = 0.6,\n",
    "#                                                          reg_alpha= 100\n",
    "                                                             ))]\n",
    "\n",
    "classification_pipe_final = Pipeline(classification_steps_final_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model valid results: 0.319986817945\n",
      "Final model test results: 0.33280726894\n"
     ]
    }
   ],
   "source": [
    "final_steps = prep_steps+classification_steps_final_xgb\n",
    "final_pipe = Pipeline(final_steps)\n",
    "\n",
    "final_pipe.fit(X_train,Y_train.apply(log_pandas).values.ravel())\n",
    "\n",
    "Y_pred_valid_count = pd.DataFrame(final_pipe.predict(X_valid)).apply(inv_log_pandas)\n",
    "valid_error_count = rmsle(Y_pred_valid_count.values.ravel(),\n",
    "                       Y_valid_count.apply(inv_log_pandas).values.ravel()\n",
    "                          )\n",
    "print \"Final model valid results:\",valid_error_count\n",
    "\n",
    "Y_pred_test_count = pd.DataFrame(final_pipe.predict(X_test)).apply(inv_log_pandas)\n",
    "test_error_count = rmsle(Y_pred_test_count.values.ravel(),\n",
    "                       Y_test_count.apply(inv_log_pandas).values.ravel()\n",
    "                          )\n",
    "print \"Final model test results:\",test_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_filepath = os.path.join(\"../\",\"models\",\"xgboost_pipeline.pkl\")\n",
    "pickle_out(model_filepath,final_pipe,compresion_mode=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime     count\n",
      "0  2011-01-20 00:00:00  7.200272\n",
      "1  2011-01-20 01:00:00  4.248402\n",
      "2  2011-01-20 02:00:00  2.501111\n",
      "3  2011-01-20 03:00:00  1.824848\n",
      "4  2011-01-20 04:00:00  1.685915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakubczakon/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "kaggle_folder = os.path.join(\"../\",\"datasets\",\"kaggle_sets\")\n",
    "kaggle_test = pd.read_csv(os.path.join(kaggle_folder,\"test.csv\"))\n",
    "full_pipeline = pickle_in(os.path.join(\"../\",\"models\",\"xgboost_pipeline.pkl\"),\n",
    "                          compresion_mode=5)\n",
    "\n",
    "X_test = kaggle_test\n",
    "kaggle_datetime = kaggle_test[[\"datetime\"]]\n",
    "Y_kaggle = pd.DataFrame(full_pipeline.predict(X_test)).apply(inv_log_pandas)\n",
    "kaggle_datetime[\"count\"] = Y_kaggle\n",
    "kaggle_datetime.to_csv(os.path.join(\"../\",\"submissions\",\n",
    "                                    \"xgboost_submission.csv\"),index=False)\n",
    "\n",
    "print kaggle_datetime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
