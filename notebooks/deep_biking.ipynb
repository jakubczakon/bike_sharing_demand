{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from __future__ import absolute_import\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import choice\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Flatten,Convolution1D,Convolution2D,LSTM\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adadelta,Adagrad,Adam,Adamax,RMSprop\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from utils.evaluation_utils import rmsle,log_pandas,inv_log_pandas\n",
    "from utils.generic_utils import pickle_out,pickle_in\n",
    "from utils.deep_learning_utils import ReportRmsleError\n",
    "import utils.preprocessing_utils as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train,Y_train) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"train_binned.pkl\"))\n",
    "(X_valid,Y_valid) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"valid_binned.pkl\"))\n",
    "(X_test,Y_test) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"test_binned.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7452, 10, 1, 27) (1722, 10, 1, 27)\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_valid = mms.transform(X_valid)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "stp_gen = prep.DataToTimeStamps(stamp_size=10,dim_out=4)\n",
    "X_train = stp_gen.fit_transform(X_train)\n",
    "X_valid = stp_gen.fit_transform(X_valid)\n",
    "X_test = stp_gen.fit_transform(X_test)\n",
    "\n",
    "Y_train = Y_train.apply(log_pandas).values.ravel()\n",
    "Y_valid = Y_valid.apply(log_pandas).values.ravel()\n",
    "# Y_train = Y_train.values.ravel()\n",
    "# Y_valid = Y_valid.values.ravel()\n",
    "\n",
    "print X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2_reg = 0.0000000000001\n",
    "l2_reg_dense = 0.0000000000001\n",
    "# channels,features = 10,27\n",
    "channels,rows,cols = 10,1,27\n",
    "\n",
    "bike_model = Sequential()\n",
    "\n",
    "#convo1\n",
    "bike_model.add(Convolution2D(32, 1,3,init =\"he_normal\",\n",
    "                             W_regularizer=l2(l=l2_reg),\n",
    "#                              input_shape = (channels,features),\n",
    "                             input_shape = (channels,rows,cols),\n",
    "#                              border_mode = \"same\"\n",
    "                            )\n",
    "              )\n",
    "bike_model.add(Activation('relu'))\n",
    "# bike_model.add(MaxPooling2D(pool_size=(2, 2),strides = (1,1)))\n",
    "# bike_model.add(Dropout(0.5))\n",
    "\n",
    "#convo2\n",
    "bike_model.add(Convolution2D(32, 1,3,init =\"he_normal\",\n",
    "                             W_regularizer=l2(l=l2_reg),\n",
    "#                              border_mode = \"same\"\n",
    "                            )\n",
    "              )\n",
    "bike_model.add(Activation('relu'))\n",
    "# bike_model.add(MaxPooling2D(pool_size=(2, 2),strides = (1,1)))\n",
    "# bike_model.add(Dropout(0.5))\n",
    "              \n",
    "#flatten\n",
    "bike_model.add(Flatten())\n",
    "\n",
    "#dense1\n",
    "bike_model.add(Dense(256,W_regularizer=l2(l=l2_reg_dense)))\n",
    "bike_model.add(Activation('relu'))\n",
    "# bike_model.add(Dropout(0.5))\n",
    "\n",
    "#output\n",
    "bike_model.add(Dense(1))\n",
    "\n",
    "bike_model.compile(loss =\"mse\",\n",
    "                  optimizer = Adagrad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE error: 1.72228461652\n",
      "RMSLE error: 1.77264747376\n",
      "RMSLE error: 1.80368796484\n",
      "RMSLE error: 1.82807291852\n",
      "RMSLE error: 1.83658319611\n",
      "RMSLE error: 1.85117438538\n",
      "RMSLE error: 1.86073891096\n",
      "RMSLE error: 1.86935325388\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0894a4bfc1a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                shuffle=False, class_weight=None, sample_weight=None)\n\u001b[0m",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    789\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rms = ReportRmsleError(X_valid,Y_valid)\n",
    "bike_model.fit(X_train, Y_train,\n",
    "               validation_data=[X_valid,Y_valid], \n",
    "               batch_size=128, nb_epoch=1000, verbose=1, \n",
    "               callbacks=[rms],\n",
    "               shuffle=False, class_weight=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train,Y_train) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"train_binned.pkl\"))\n",
    "(X_valid,Y_valid) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"valid_binned.pkl\"))\n",
    "(X_test,Y_test) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"test_binned.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7452, 10, 27) (1722, 10, 27)\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_valid = mms.transform(X_valid)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "stp_gen = prep.DataToTimeStamps(stamp_size=10,dim_out=3)\n",
    "X_train = stp_gen.fit_transform(X_train)\n",
    "X_valid = stp_gen.fit_transform(X_valid)\n",
    "X_test = stp_gen.fit_transform(X_test)\n",
    "\n",
    "Y_train = Y_train.apply(log_pandas).values.ravel()\n",
    "Y_valid = Y_valid.apply(log_pandas).values.ravel()\n",
    "# Y_train = Y_train.values.ravel()\n",
    "# Y_valid = Y_valid.values.ravel()\n",
    "\n",
    "print X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2_reg = 0.0000000000001\n",
    "l2_reg_dense = 0.0000000000001\n",
    "\n",
    "bike_lstm_model = Sequential()\n",
    "bike_lstm_model.add(LSTM(10, input_dim=27))\n",
    "bike_lstm_model.add(Dense(256))\n",
    "bike_lstm_model.add(Dense(1))\n",
    "\n",
    "bike_lstm_model.compile(loss =\"mse\",\n",
    "                  optimizer = Adagrad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7452 samples, validate on 1722 samples\n",
      "Epoch 1/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 2.0649\n",
      "\n",
      "RMSLE error: 1.80490051972\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 2.0622 - val_loss: 2.4989\n",
      "Epoch 2/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 1.4619\n",
      "\n",
      "RMSLE error: 1.76170784402\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 1.4606 - val_loss: 1.9262\n",
      "Epoch 3/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 1.2458\n",
      "\n",
      "RMSLE error: 1.75631323055\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 1.2447 - val_loss: 1.5268\n",
      "Epoch 4/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 1.0424\n",
      "\n",
      "RMSLE error: 1.7671939296\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 1.0415 - val_loss: 1.2049\n",
      "Epoch 5/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.8669\n",
      "\n",
      "RMSLE error: 1.79317765146\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.8661 - val_loss: 0.9535\n",
      "Epoch 6/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.7341\n",
      "\n",
      "RMSLE error: 1.82671750747\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.7334 - val_loss: 0.7795\n",
      "Epoch 7/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.6448\n",
      "\n",
      "RMSLE error: 1.85385715932\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.6441 - val_loss: 0.6719\n",
      "Epoch 8/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.5864\n",
      "\n",
      "RMSLE error: 1.87060111084\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.5857 - val_loss: 0.6018\n",
      "Epoch 9/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.5458\n",
      "\n",
      "RMSLE error: 1.88007392395\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.5451 - val_loss: 0.5511\n",
      "Epoch 10/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.5155\n",
      "\n",
      "RMSLE error: 1.88535936548\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.5147 - val_loss: 0.5121\n",
      "Epoch 11/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4917\n",
      "\n",
      "RMSLE error: 1.88847653032\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4909 - val_loss: 0.4814\n",
      "Epoch 12/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4723\n",
      "\n",
      "RMSLE error: 1.89059749634\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4715 - val_loss: 0.4567\n",
      "Epoch 13/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4561\n",
      "\n",
      "RMSLE error: 1.89232184672\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4553 - val_loss: 0.4365\n",
      "Epoch 14/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4423\n",
      "\n",
      "RMSLE error: 1.8938504685\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 0.4415 - val_loss: 0.4199\n",
      "Epoch 15/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4304\n",
      "\n",
      "RMSLE error: 1.89540432049\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4296 - val_loss: 0.4057\n",
      "Epoch 16/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4198\n",
      "\n",
      "RMSLE error: 1.8966599747\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4190 - val_loss: 0.3937\n",
      "Epoch 17/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4105\n",
      "\n",
      "RMSLE error: 1.89781772091\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4097 - val_loss: 0.3832\n",
      "Epoch 18/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4021\n",
      "\n",
      "RMSLE error: 1.89895445798\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4013 - val_loss: 0.3739\n",
      "Epoch 19/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3945\n",
      "\n",
      "RMSLE error: 1.90003781308\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.3937 - val_loss: 0.3656\n",
      "Epoch 20/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3876\n",
      "\n",
      "RMSLE error: 1.9010495042\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.3868 - val_loss: 0.3583\n",
      "Epoch 21/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3813\n",
      "\n",
      "RMSLE error: 1.9020538283\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3805 - val_loss: 0.3516\n",
      "Epoch 22/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3755\n",
      "\n",
      "RMSLE error: 1.9031416404\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3747 - val_loss: 0.3456\n",
      "Epoch 23/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3701\n",
      "\n",
      "RMSLE error: 1.9042125855\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3693 - val_loss: 0.3401\n",
      "Epoch 24/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3651\n",
      "\n",
      "RMSLE error: 1.90517634986\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3643 - val_loss: 0.3351\n",
      "Epoch 25/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3604\n",
      "\n",
      "RMSLE error: 1.90614286557\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3597 - val_loss: 0.3305\n",
      "Epoch 26/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3561\n",
      "\n",
      "RMSLE error: 1.90718831752\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3554 - val_loss: 0.3263\n",
      "Epoch 27/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3520\n",
      "\n",
      "RMSLE error: 1.90816069876\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3513 - val_loss: 0.3224\n",
      "Epoch 28/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3482\n",
      "\n",
      "RMSLE error: 1.90911442583\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3474 - val_loss: 0.3188\n",
      "Epoch 29/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3445\n",
      "\n",
      "RMSLE error: 1.91007487137\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3438 - val_loss: 0.3155\n",
      "Epoch 30/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3411\n",
      "\n",
      "RMSLE error: 1.91096591422\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3404 - val_loss: 0.3124\n",
      "Epoch 31/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3379\n",
      "\n",
      "RMSLE error: 1.91186005158\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3372 - val_loss: 0.3095\n",
      "Epoch 32/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3348\n",
      "\n",
      "RMSLE error: 1.91268695332\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3341 - val_loss: 0.3068\n",
      "Epoch 33/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3319\n",
      "\n",
      "RMSLE error: 1.91350944027\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.3312 - val_loss: 0.3042\n",
      "Epoch 34/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3292\n",
      "\n",
      "RMSLE error: 1.91431287546\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3285 - val_loss: 0.3017\n",
      "Epoch 35/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3265\n",
      "\n",
      "RMSLE error: 1.91508347778\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3259 - val_loss: 0.2994\n",
      "Epoch 36/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3240\n",
      "\n",
      "RMSLE error: 1.91583745176\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3234 - val_loss: 0.2971\n",
      "Epoch 37/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3216\n",
      "\n",
      "RMSLE error: 1.91656389557\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3210 - val_loss: 0.2950\n",
      "Epoch 38/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3193\n",
      "\n",
      "RMSLE error: 1.9172869782\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3187 - val_loss: 0.2929\n",
      "Epoch 39/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3171\n",
      "\n",
      "RMSLE error: 1.91801535147\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3164 - val_loss: 0.2910\n",
      "Epoch 40/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3150\n",
      "\n",
      "RMSLE error: 1.91873807005\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3143 - val_loss: 0.2891\n",
      "Epoch 41/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3129\n",
      "\n",
      "RMSLE error: 1.919415089\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3123 - val_loss: 0.2873\n",
      "Epoch 42/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3110\n",
      "\n",
      "RMSLE error: 1.92007251194\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3103 - val_loss: 0.2856\n",
      "Epoch 43/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3091\n",
      "\n",
      "RMSLE error: 1.92072249123\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3084 - val_loss: 0.2839\n",
      "Epoch 44/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3072\n",
      "\n",
      "RMSLE error: 1.92137650939\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3066 - val_loss: 0.2823\n",
      "Epoch 45/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3055\n",
      "\n",
      "RMSLE error: 1.92199472139\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3048 - val_loss: 0.2807\n",
      "Epoch 46/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3038\n",
      "\n",
      "RMSLE error: 1.92260932887\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3031 - val_loss: 0.2793\n",
      "Epoch 47/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3021\n",
      "\n",
      "RMSLE error: 1.92320788938\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3015 - val_loss: 0.2778\n",
      "Epoch 48/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3005\n",
      "\n",
      "RMSLE error: 1.92378071592\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2999 - val_loss: 0.2764\n",
      "Epoch 49/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2990\n",
      "\n",
      "RMSLE error: 1.92435298685\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2984 - val_loss: 0.2751\n",
      "Epoch 50/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2975\n",
      "\n",
      "RMSLE error: 1.92491002109\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2969 - val_loss: 0.2738\n",
      "Epoch 51/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2961\n",
      "\n",
      "RMSLE error: 1.92545429344\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2954 - val_loss: 0.2725\n",
      "Epoch 52/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2946\n",
      "\n",
      "RMSLE error: 1.92597796088\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2940 - val_loss: 0.2713\n",
      "Epoch 53/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2933\n",
      "\n",
      "RMSLE error: 1.92650916864\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2927 - val_loss: 0.2701\n",
      "Epoch 54/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2919\n",
      "\n",
      "RMSLE error: 1.92701731518\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2913 - val_loss: 0.2689\n",
      "Epoch 55/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2906\n",
      "\n",
      "RMSLE error: 1.92751267989\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2900 - val_loss: 0.2678\n",
      "Epoch 56/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2894\n",
      "\n",
      "RMSLE error: 1.92799755188\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2888 - val_loss: 0.2667\n",
      "Epoch 57/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2881\n",
      "\n",
      "RMSLE error: 1.92848507094\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2875 - val_loss: 0.2656\n",
      "Epoch 58/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2869\n",
      "\n",
      "RMSLE error: 1.92894911515\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2863 - val_loss: 0.2646\n",
      "Epoch 59/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2858\n",
      "\n",
      "RMSLE error: 1.92941585195\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2851 - val_loss: 0.2635\n",
      "Epoch 60/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2846\n",
      "\n",
      "RMSLE error: 1.92987885033\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2840 - val_loss: 0.2626\n",
      "Epoch 61/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2835\n",
      "\n",
      "RMSLE error: 1.93031455253\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2829 - val_loss: 0.2616\n",
      "Epoch 62/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2824\n",
      "\n",
      "RMSLE error: 1.93074341474\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2817 - val_loss: 0.2606\n",
      "Epoch 63/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2813\n",
      "\n",
      "RMSLE error: 1.93117663536\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2807 - val_loss: 0.2597\n",
      "Epoch 64/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2802\n",
      "\n",
      "RMSLE error: 1.93160109195\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2796 - val_loss: 0.2588\n",
      "Epoch 65/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2792\n",
      "\n",
      "RMSLE error: 1.9320185524\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2785 - val_loss: 0.2578\n",
      "Epoch 66/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2781\n",
      "\n",
      "RMSLE error: 1.93243077486\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2775 - val_loss: 0.2570\n",
      "Epoch 67/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2771\n",
      "\n",
      "RMSLE error: 1.93284598921\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2765 - val_loss: 0.2561\n",
      "Epoch 68/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2761\n",
      "\n",
      "RMSLE error: 1.93326254857\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2755 - val_loss: 0.2552\n",
      "Epoch 69/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2751\n",
      "\n",
      "RMSLE error: 1.93367006911\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2745 - val_loss: 0.2544\n",
      "Epoch 70/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2742\n",
      "\n",
      "RMSLE error: 1.93406285091\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2736 - val_loss: 0.2536\n",
      "Epoch 71/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2732\n",
      "\n",
      "RMSLE error: 1.93445822993\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2726 - val_loss: 0.2527\n",
      "Epoch 72/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2723\n",
      "\n",
      "RMSLE error: 1.93485741045\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2717 - val_loss: 0.2519\n",
      "Epoch 73/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2714\n",
      "\n",
      "RMSLE error: 1.93524411697\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2708 - val_loss: 0.2511\n",
      "Epoch 74/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2705\n",
      "\n",
      "RMSLE error: 1.93562242979\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2699 - val_loss: 0.2504\n",
      "Epoch 75/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2696\n",
      "\n",
      "RMSLE error: 1.93598884845\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2690 - val_loss: 0.2496\n",
      "Epoch 76/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2687\n",
      "\n",
      "RMSLE error: 1.93637016298\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2681 - val_loss: 0.2489\n",
      "Epoch 77/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2678\n",
      "\n",
      "RMSLE error: 1.93673016064\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2672 - val_loss: 0.2481\n",
      "Epoch 78/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2669\n",
      "\n",
      "RMSLE error: 1.93707767912\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2663 - val_loss: 0.2474\n",
      "Epoch 79/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2661\n",
      "\n",
      "RMSLE error: 1.93742591853\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2655 - val_loss: 0.2467\n",
      "Epoch 80/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2652\n",
      "\n",
      "RMSLE error: 1.93778216368\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2646 - val_loss: 0.2459\n",
      "Epoch 81/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2644\n",
      "\n",
      "RMSLE error: 1.93812965322\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2638 - val_loss: 0.2452\n",
      "Epoch 82/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2636\n",
      "\n",
      "RMSLE error: 1.93847743317\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2630 - val_loss: 0.2445\n",
      "Epoch 83/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2628\n",
      "\n",
      "RMSLE error: 1.93882361277\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2622 - val_loss: 0.2439\n",
      "Epoch 84/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2620\n",
      "\n",
      "RMSLE error: 1.93916275033\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2614 - val_loss: 0.2432\n",
      "Epoch 85/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2612\n",
      "\n",
      "RMSLE error: 1.9394967911\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 0.2606 - val_loss: 0.2425\n",
      "Epoch 86/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2604\n",
      "\n",
      "RMSLE error: 1.93982889829\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2598 - val_loss: 0.2419\n",
      "Epoch 87/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2596\n",
      "\n",
      "RMSLE error: 1.94017322261\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.2590 - val_loss: 0.2412\n",
      "Epoch 88/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2588\n",
      "\n",
      "RMSLE error: 1.94051023277\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2582 - val_loss: 0.2406\n",
      "Epoch 89/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2581\n",
      "\n",
      "RMSLE error: 1.9408456233\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.2575 - val_loss: 0.2400\n",
      "Epoch 90/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2573\n",
      "\n",
      "RMSLE error: 1.94117760008\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2567 - val_loss: 0.2393\n",
      "Epoch 91/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2566\n",
      "\n",
      "RMSLE error: 1.9414857804\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2560 - val_loss: 0.2387\n",
      "Epoch 92/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2558\n",
      "\n",
      "RMSLE error: 1.94179955123\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2552 - val_loss: 0.2381\n",
      "Epoch 93/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2551\n",
      "\n",
      "RMSLE error: 1.94210652977\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2545 - val_loss: 0.2375\n",
      "Epoch 94/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2544\n",
      "\n",
      "RMSLE error: 1.94241861058\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2538 - val_loss: 0.2369\n",
      "Epoch 95/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2536\n",
      "\n",
      "RMSLE error: 1.94272298919\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2531 - val_loss: 0.2364\n",
      "Epoch 96/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2529\n",
      "\n",
      "RMSLE error: 1.94301226101\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2524 - val_loss: 0.2358\n",
      "Epoch 97/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "\n",
      "RMSLE error: 1.94330890098\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2516 - val_loss: 0.2352\n",
      "Epoch 98/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2515\n",
      "\n",
      "RMSLE error: 1.94360438538\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2509 - val_loss: 0.2347\n",
      "Epoch 99/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2508\n",
      "\n",
      "RMSLE error: 1.94389140778\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2502 - val_loss: 0.2341\n",
      "Epoch 100/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2501\n",
      "\n",
      "RMSLE error: 1.94418230248\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2496 - val_loss: 0.2335\n",
      "Epoch 101/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "\n",
      "RMSLE error: 1.94446918748\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2489 - val_loss: 0.2330\n",
      "Epoch 102/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "\n",
      "RMSLE error: 1.94474820136\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2482 - val_loss: 0.2325\n",
      "Epoch 103/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "\n",
      "RMSLE error: 1.94502423935\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2475 - val_loss: 0.2319\n",
      "Epoch 104/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "\n",
      "RMSLE error: 1.94529383248\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2469 - val_loss: 0.2314\n",
      "Epoch 105/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "\n",
      "RMSLE error: 1.94555734346\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2462 - val_loss: 0.2309\n",
      "Epoch 106/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2461\n",
      "\n",
      "RMSLE error: 1.94582097089\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2455 - val_loss: 0.2304\n",
      "Epoch 107/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "\n",
      "RMSLE error: 1.94609248685\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2449 - val_loss: 0.2299\n",
      "Epoch 108/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "\n",
      "RMSLE error: 1.94635264218\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2442 - val_loss: 0.2294\n",
      "Epoch 109/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "\n",
      "RMSLE error: 1.94660011821\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2436 - val_loss: 0.2289\n",
      "Epoch 110/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "\n",
      "RMSLE error: 1.94685113793\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2430 - val_loss: 0.2284\n",
      "Epoch 111/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2429\n",
      "\n",
      "RMSLE error: 1.94710120972\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2423 - val_loss: 0.2279\n",
      "Epoch 112/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2422\n",
      "\n",
      "RMSLE error: 1.94734682167\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2417 - val_loss: 0.2274\n",
      "Epoch 113/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2416\n",
      "\n",
      "RMSLE error: 1.94759247759\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2411 - val_loss: 0.2269\n",
      "Epoch 114/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2410\n",
      "\n",
      "RMSLE error: 1.94783812178\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2404 - val_loss: 0.2264\n",
      "Epoch 115/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2404\n",
      "\n",
      "RMSLE error: 1.94807752561\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2398 - val_loss: 0.2260\n",
      "Epoch 116/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2398\n",
      "\n",
      "RMSLE error: 1.94831394945\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2392 - val_loss: 0.2255\n",
      "Epoch 117/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2391\n",
      "\n",
      "RMSLE error: 1.94854981525\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2386 - val_loss: 0.2250\n",
      "Epoch 118/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2385\n",
      "\n",
      "RMSLE error: 1.94877368815\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2380 - val_loss: 0.2245\n",
      "Epoch 119/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2379\n",
      "\n",
      "RMSLE error: 1.94899178798\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2374 - val_loss: 0.2241\n",
      "Epoch 120/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2373\n",
      "\n",
      "RMSLE error: 1.94922377051\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2368 - val_loss: 0.2236\n",
      "Epoch 121/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2367\n",
      "\n",
      "RMSLE error: 1.94943857407\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2362 - val_loss: 0.2232\n",
      "Epoch 122/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2361\n",
      "\n",
      "RMSLE error: 1.94967320244\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2356 - val_loss: 0.2227\n",
      "Epoch 123/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2355\n",
      "\n",
      "RMSLE error: 1.94989330721\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2350 - val_loss: 0.2223\n",
      "Epoch 124/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2350\n",
      "\n",
      "RMSLE error: 1.95011469835\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2344 - val_loss: 0.2218\n",
      "Epoch 125/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2344\n",
      "\n",
      "RMSLE error: 1.95033386792\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2338 - val_loss: 0.2214\n",
      "Epoch 126/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2338\n",
      "\n",
      "RMSLE error: 1.95054640593\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2332 - val_loss: 0.2209\n",
      "Epoch 127/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2332\n",
      "\n",
      "RMSLE error: 1.95076023329\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2327 - val_loss: 0.2205\n",
      "Epoch 128/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2326\n",
      "\n",
      "RMSLE error: 1.95097006565\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2321 - val_loss: 0.2200\n",
      "Epoch 129/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2320\n",
      "\n",
      "RMSLE error: 1.95118247793\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2315 - val_loss: 0.2196\n",
      "Epoch 130/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2315\n",
      "\n",
      "RMSLE error: 1.95140138633\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2309 - val_loss: 0.2192\n",
      "Epoch 131/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2309\n",
      "\n",
      "RMSLE error: 1.95160896311\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2304 - val_loss: 0.2188\n",
      "Epoch 132/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2303\n",
      "\n",
      "RMSLE error: 1.95181127183\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2298 - val_loss: 0.2183\n",
      "Epoch 133/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2297\n",
      "\n",
      "RMSLE error: 1.9520127617\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2292 - val_loss: 0.2179\n",
      "Epoch 134/10000\n",
      "7168/7452 [===========================>..] - ETA: 0s - loss: 0.2306Traceback (most recent call last):\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 970, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 233, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 267, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/inspect.py\", line 500, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/posixpath.py\", line 375, in realpath\n",
      "    path, ok = _joinrealpath('', filename, {})\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/posixpath.py\", line 399, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[0;32m   1878\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1879\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1880\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1242\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1148\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1150\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m             )\n\u001b[0;32m   1152\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1002\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecords\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mformat_records\u001b[1;34m(self, records)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[0mabspath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m             \u001b[1;31m#print '*** record:',file,lnum,func,lines,index  # dbg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "rms = ReportRmsleError(X_valid,Y_valid)\n",
    "bike_lstm_model.fit(X_train, Y_train,\n",
    "               validation_data=[X_valid,Y_valid], \n",
    "               batch_size=128, nb_epoch=10000, verbose=1, \n",
    "               callbacks=[rms],\n",
    "               shuffle=False, class_weight=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
