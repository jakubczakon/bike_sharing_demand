{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from __future__ import absolute_import\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import choice\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Flatten,Convolution1D,Convolution2D,LSTM\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adadelta,Adagrad,Adam,Adamax,RMSprop\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from utils.evaluation_utils import rmsle,log_pandas,inv_log_pandas\n",
    "from utils.generic_utils import pickle_out,pickle_in\n",
    "from utils.deep_learning_utils import ReportRmsleError\n",
    "import utils.preprocessing_utils as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train,Y_train) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"train_binned.pkl\"))\n",
    "(X_valid,Y_valid) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"valid_binned.pkl\"))\n",
    "(X_test,Y_test) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"test_binned.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7452, 10, 1, 27) (1722, 10, 1, 27)\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_valid = mms.transform(X_valid)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "stp_gen = prep.DataToTimeStamps(stamp_size=10,dim_out=4)\n",
    "X_train = stp_gen.fit_transform(X_train)\n",
    "X_valid = stp_gen.fit_transform(X_valid)\n",
    "X_test = stp_gen.fit_transform(X_test)\n",
    "\n",
    "Y_train = Y_train.apply(log_pandas).values.ravel()\n",
    "Y_valid = Y_valid.apply(log_pandas).values.ravel()\n",
    "# Y_train = Y_train.values.ravel()\n",
    "# Y_valid = Y_valid.values.ravel()\n",
    "\n",
    "print X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2_reg = 0.0000000000001\n",
    "l2_reg_dense = 0.0000000000001\n",
    "# channels,features = 10,27\n",
    "channels,rows,cols = 10,1,27\n",
    "\n",
    "bike_model = Sequential()\n",
    "\n",
    "#convo1\n",
    "bike_model.add(Convolution2D(32, 1,3,init =\"he_normal\",\n",
    "                             W_regularizer=l2(l=l2_reg),\n",
    "#                              input_shape = (channels,features),\n",
    "                             input_shape = (channels,rows,cols),\n",
    "#                              border_mode = \"same\"\n",
    "                            )\n",
    "              )\n",
    "bike_model.add(Activation('relu'))\n",
    "# bike_model.add(MaxPooling2D(pool_size=(2, 2),strides = (1,1)))\n",
    "# bike_model.add(Dropout(0.5))\n",
    "\n",
    "#convo2\n",
    "bike_model.add(Convolution2D(32, 1,3,init =\"he_normal\",\n",
    "                             W_regularizer=l2(l=l2_reg),\n",
    "#                              border_mode = \"same\"\n",
    "                            )\n",
    "              )\n",
    "bike_model.add(Activation('relu'))\n",
    "# bike_model.add(MaxPooling2D(pool_size=(2, 2),strides = (1,1)))\n",
    "# bike_model.add(Dropout(0.5))\n",
    "              \n",
    "#flatten\n",
    "bike_model.add(Flatten())\n",
    "\n",
    "#dense1\n",
    "bike_model.add(Dense(256,W_regularizer=l2(l=l2_reg_dense)))\n",
    "bike_model.add(Activation('relu'))\n",
    "# bike_model.add(Dropout(0.5))\n",
    "\n",
    "#output\n",
    "bike_model.add(Dense(1))\n",
    "\n",
    "bike_model.compile(loss =\"mse\",\n",
    "                  optimizer = Adagrad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7452 samples, validate on 1722 samples\n",
      "Epoch 1/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7398.0266\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7381.1651 - val_loss: 7525.0197\n",
      "Epoch 2/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7369.0392\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 7352.2428 - val_loss: 7506.8191\n",
      "Epoch 3/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7356.1709\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7339.3923 - val_loss: 7492.7152\n",
      "Epoch 4/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7342.8313\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7326.0513 - val_loss: 7479.9192\n",
      "Epoch 5/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7329.6395\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 7312.8826 - val_loss: 7467.3501\n",
      "Epoch 6/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7316.2647\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 7299.5203 - val_loss: 7455.4496\n",
      "Epoch 7/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7303.4067\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 7286.6863 - val_loss: 7443.1679\n",
      "Epoch 8/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7290.6274\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 7273.9196 - val_loss: 7432.3535\n",
      "Epoch 9/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7277.5287\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 7260.8412 - val_loss: 7420.8759\n",
      "Epoch 10/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7264.7030\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 7248.0358 - val_loss: 7411.2831\n",
      "Epoch 11/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7251.8450\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7235.2012 - val_loss: 7399.6654\n",
      "Epoch 12/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7239.2199\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 7222.5954 - val_loss: 7388.5854\n",
      "Epoch 13/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7226.1790\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 7209.5836 - val_loss: 7379.0925\n",
      "Epoch 14/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7213.4942\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 7196.9167 - val_loss: 7368.6607\n",
      "Epoch 15/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7200.8066\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7184.2580 - val_loss: 7358.6929\n",
      "Epoch 16/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7188.1573\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7171.6283 - val_loss: 7348.8520\n",
      "Epoch 17/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7175.4162\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7158.9067 - val_loss: 7335.8571\n",
      "Epoch 18/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7163.4403\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7146.9543 - val_loss: 7328.1618\n",
      "Epoch 19/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7150.7277\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 7134.2567 - val_loss: 7317.6824\n",
      "Epoch 20/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7138.4002\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 7121.9526 - val_loss: 7306.9815\n",
      "Epoch 21/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7125.9450\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 7109.5185 - val_loss: 7297.5302\n",
      "Epoch 22/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7113.6811\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 7097.2766 - val_loss: 7286.5697\n",
      "Epoch 23/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7101.9641\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7085.5790 - val_loss: 7276.8306\n",
      "Epoch 24/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7090.2103\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7073.8365 - val_loss: 7267.3196\n",
      "Epoch 25/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7078.4720\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 7062.1140 - val_loss: 7257.2416\n",
      "Epoch 26/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7066.2155\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 8s - loss: 7049.8705 - val_loss: 7246.7154\n",
      "Epoch 27/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7054.7908\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7038.4728 - val_loss: 7236.9249\n",
      "Epoch 28/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7043.1513\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7026.8539 - val_loss: 7228.0239\n",
      "Epoch 29/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7031.4762\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7015.1898 - val_loss: 7217.7543\n",
      "Epoch 30/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7020.1917\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 7003.9207 - val_loss: 7208.8314\n",
      "Epoch 31/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 7008.7896\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6992.5309 - val_loss: 7199.3293\n",
      "Epoch 32/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6997.0873\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6980.8506 - val_loss: 7190.3106\n",
      "Epoch 33/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6985.5963\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6969.3807 - val_loss: 7180.7594\n",
      "Epoch 34/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6974.1451\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6957.9426 - val_loss: 7171.8405\n",
      "Epoch 35/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6963.1579\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6946.9718 - val_loss: 7161.8633\n",
      "Epoch 36/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6952.0125\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6935.8380 - val_loss: 7153.2229\n",
      "Epoch 37/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6940.6976\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6924.5307 - val_loss: 7144.8462\n",
      "Epoch 38/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6929.5462\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6913.3913 - val_loss: 7134.6808\n",
      "Epoch 39/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6918.4273\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6902.2962 - val_loss: 7126.3646\n",
      "Epoch 40/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6907.3058\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6891.1892 - val_loss: 7116.2911\n",
      "Epoch 41/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6896.8368\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6880.7366 - val_loss: 7108.1873\n",
      "Epoch 42/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6886.0215\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6869.9307 - val_loss: 7097.8350\n",
      "Epoch 43/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6874.8959\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6858.8244 - val_loss: 7090.3999\n",
      "Epoch 44/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6864.3302\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6848.2784 - val_loss: 7080.8618\n",
      "Epoch 45/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6853.7367\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6837.7031 - val_loss: 7072.8562\n",
      "Epoch 46/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6843.3116\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6827.2874 - val_loss: 7065.2023\n",
      "Epoch 47/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6832.3872\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6816.3742 - val_loss: 7055.4918\n",
      "Epoch 48/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6822.2114\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6806.2125 - val_loss: 7046.3407\n",
      "Epoch 49/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6811.6139\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6795.6300 - val_loss: 7037.6256\n",
      "Epoch 50/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6801.2766\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6785.3108 - val_loss: 7029.3210\n",
      "Epoch 51/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6791.2291\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6775.2720 - val_loss: 7021.9757\n",
      "Epoch 52/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6780.6422\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6764.7059 - val_loss: 7013.7489\n",
      "Epoch 53/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6770.5593\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 6754.6431 - val_loss: 7004.0298\n",
      "Epoch 54/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6760.3878\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6744.4914 - val_loss: 6995.8825\n",
      "Epoch 55/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6750.3604\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6734.4770 - val_loss: 6987.5175\n",
      "Epoch 56/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6740.1758\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6724.3030 - val_loss: 6980.5818\n",
      "Epoch 57/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6729.6456\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 9s - loss: 6713.7992 - val_loss: 6972.6237\n",
      "Epoch 58/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6719.7250\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6703.9010 - val_loss: 6964.3081\n",
      "Epoch 59/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6709.6423\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6693.8272 - val_loss: 6956.5586\n",
      "Epoch 60/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6699.6615\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6683.8654 - val_loss: 6948.6045\n",
      "Epoch 61/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6689.9341\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6674.1501 - val_loss: 6941.0797\n",
      "Epoch 62/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6679.7822\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6664.0120 - val_loss: 6933.3375\n",
      "Epoch 63/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6670.2070\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 8s - loss: 6654.4455 - val_loss: 6926.0368\n",
      "Epoch 64/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6660.1215\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6644.3729 - val_loss: 6917.6448\n",
      "Epoch 65/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6650.3784\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6634.6529 - val_loss: 6909.4450\n",
      "Epoch 66/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6640.6749\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6624.9628 - val_loss: 6901.8811\n",
      "Epoch 67/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6631.0148\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6615.3210 - val_loss: 6894.0900\n",
      "Epoch 68/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6621.1327\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6605.4517 - val_loss: 6886.0727\n",
      "Epoch 69/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6611.6661\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6596.0026 - val_loss: 6878.4338\n",
      "Epoch 70/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6601.9019\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6586.2616 - val_loss: 6870.4132\n",
      "Epoch 71/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6592.5001\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6576.8748 - val_loss: 6862.6402\n",
      "Epoch 72/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6582.8575\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6567.2422 - val_loss: 6855.3366\n",
      "Epoch 73/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6573.2233\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6557.6223 - val_loss: 6848.3853\n",
      "Epoch 74/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6563.8747\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6548.2822 - val_loss: 6841.2228\n",
      "Epoch 75/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6554.2308\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6538.6506 - val_loss: 6833.9468\n",
      "Epoch 76/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6544.9472\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6529.3730 - val_loss: 6827.0792\n",
      "Epoch 77/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6535.2457\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6519.6871 - val_loss: 6818.6983\n",
      "Epoch 78/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6526.1945\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6510.6463 - val_loss: 6812.1217\n",
      "Epoch 79/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6516.8477\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6501.3043 - val_loss: 6804.1294\n",
      "Epoch 80/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6507.6073\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6492.0750 - val_loss: 6797.9028\n",
      "Epoch 81/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6498.0627\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6482.5379 - val_loss: 6789.3376\n",
      "Epoch 82/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6489.2424\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6473.7309 - val_loss: 6782.2606\n",
      "Epoch 83/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6480.2487\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6464.7538 - val_loss: 6774.5998\n",
      "Epoch 84/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6470.9996\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6455.5196 - val_loss: 6766.2045\n",
      "Epoch 85/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6461.9612\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6446.4905 - val_loss: 6760.2208\n",
      "Epoch 86/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6452.6544\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6437.1987 - val_loss: 6752.3957\n",
      "Epoch 87/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6443.8300\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6428.3850 - val_loss: 6745.2218\n",
      "Epoch 88/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6434.9993\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6419.5743 - val_loss: 6738.8678\n",
      "Epoch 89/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6426.0199\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6410.6088 - val_loss: 6731.5928\n",
      "Epoch 90/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6417.0901\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6401.6973 - val_loss: 6724.2971\n",
      "Epoch 91/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6408.0743\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 9s - loss: 6392.6960 - val_loss: 6716.8726\n",
      "Epoch 92/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6399.5059\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 9s - loss: 6384.1483 - val_loss: 6709.1091\n",
      "Epoch 93/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6390.6597\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6375.3168 - val_loss: 6703.0354\n",
      "Epoch 94/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6381.7865\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6366.4660 - val_loss: 6695.8917\n",
      "Epoch 95/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6373.2138\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6357.9105 - val_loss: 6688.8338\n",
      "Epoch 96/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6364.5066\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6349.2209 - val_loss: 6683.2215\n",
      "Epoch 97/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6355.8393\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6340.5773 - val_loss: 6674.3593\n",
      "Epoch 98/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6347.2313\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6331.9904 - val_loss: 6667.6640\n",
      "Epoch 99/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6338.5636\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6323.3434 - val_loss: 6660.7095\n",
      "Epoch 100/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6330.1826\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6314.9809 - val_loss: 6653.0531\n",
      "Epoch 101/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6321.7211\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6306.5375 - val_loss: 6646.6905\n",
      "Epoch 102/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6313.1473\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6297.9848 - val_loss: 6640.0290\n",
      "Epoch 103/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6305.0137\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6289.8750 - val_loss: 6633.4048\n",
      "Epoch 104/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6296.3472\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6281.2267 - val_loss: 6625.7726\n",
      "Epoch 105/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6288.2966\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6273.1951 - val_loss: 6619.1574\n",
      "Epoch 106/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6279.6487\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6264.5684 - val_loss: 6613.0971\n",
      "Epoch 107/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6271.2592\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6256.2010 - val_loss: 6604.5217\n",
      "Epoch 108/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6263.1247\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6248.0917 - val_loss: 6599.4168\n",
      "Epoch 109/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6254.5350\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 8s - loss: 6239.5168 - val_loss: 6592.0097\n",
      "Epoch 110/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6246.4179\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6231.4196 - val_loss: 6584.3227\n",
      "Epoch 111/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6238.0787\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6223.0930 - val_loss: 6578.2292\n",
      "Epoch 112/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6229.8171\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6214.8484 - val_loss: 6572.0579\n",
      "Epoch 113/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6221.3965\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6206.4433 - val_loss: 6564.2615\n",
      "Epoch 114/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6213.3814\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6198.4494 - val_loss: 6558.7277\n",
      "Epoch 115/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6204.8504\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6189.9363 - val_loss: 6550.9903\n",
      "Epoch 116/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6196.8181\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6181.9161 - val_loss: 6544.9735\n",
      "Epoch 117/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6188.4361\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6173.5556 - val_loss: 6538.8143\n",
      "Epoch 118/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6180.6560\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6165.7885 - val_loss: 6532.4406\n",
      "Epoch 119/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6172.4919\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6157.6441 - val_loss: 6524.8941\n",
      "Epoch 120/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6164.4145\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6149.5779 - val_loss: 6519.7291\n",
      "Epoch 121/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6156.3506\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6141.5327 - val_loss: 6514.6546\n",
      "Epoch 122/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6148.4052\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6133.6079 - val_loss: 6506.9195\n",
      "Epoch 123/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6140.3386\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6125.5526 - val_loss: 6501.0102\n",
      "Epoch 124/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6132.4317\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6117.6692 - val_loss: 6495.0598\n",
      "Epoch 125/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6124.6805\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6109.9353 - val_loss: 6489.3940\n",
      "Epoch 126/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6116.6719\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6101.9492 - val_loss: 6484.1943\n",
      "Epoch 127/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6108.6751\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 6093.9688 - val_loss: 6477.3315\n",
      "Epoch 128/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6100.9082\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6086.2277 - val_loss: 6471.9344\n",
      "Epoch 129/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6092.9847\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6078.3212 - val_loss: 6465.8740\n",
      "Epoch 130/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6085.0971\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6070.4576 - val_loss: 6459.9771\n",
      "Epoch 131/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6077.2644\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6062.6404 - val_loss: 6454.0891\n",
      "Epoch 132/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6069.5509\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6054.9566 - val_loss: 6448.5138\n",
      "Epoch 133/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6061.5386\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 8s - loss: 6046.9631 - val_loss: 6442.8662\n",
      "Epoch 134/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6053.9406\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6039.3875 - val_loss: 6436.1997\n",
      "Epoch 135/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6046.3036\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6031.7756 - val_loss: 6431.0063\n",
      "Epoch 136/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6038.3698\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6023.8623 - val_loss: 6425.8422\n",
      "Epoch 137/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6030.4479\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6015.9582 - val_loss: 6418.4864\n",
      "Epoch 138/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6022.8821\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 6008.4188 - val_loss: 6414.9242\n",
      "Epoch 139/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6014.9088\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 6000.4647 - val_loss: 6408.1412\n",
      "Epoch 140/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 6007.3302\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5992.8996 - val_loss: 6401.1207\n",
      "Epoch 141/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5999.6923\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5985.2798 - val_loss: 6397.7137\n",
      "Epoch 142/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5991.9254\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5977.5324 - val_loss: 6390.9413\n",
      "Epoch 143/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5984.5775\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5970.2030 - val_loss: 6385.7570\n",
      "Epoch 144/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5976.7437\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 5962.3788 - val_loss: 6380.1970\n",
      "Epoch 145/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5969.6842\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5955.3423 - val_loss: 6374.6213\n",
      "Epoch 146/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5962.0252\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5947.7026 - val_loss: 6368.9059\n",
      "Epoch 147/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5954.7509\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5940.4460 - val_loss: 6363.1695\n",
      "Epoch 148/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5946.9729\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5932.6868 - val_loss: 6358.2913\n",
      "Epoch 149/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5939.5479\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5925.2804 - val_loss: 6352.6513\n",
      "Epoch 150/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5932.3265\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 5918.0806 - val_loss: 6347.2285\n",
      "Epoch 151/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5924.6119\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5910.3865 - val_loss: 6342.0360\n",
      "Epoch 152/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5917.3299\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5903.1208 - val_loss: 6336.1766\n",
      "Epoch 153/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5910.0659\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5895.8803 - val_loss: 6330.2037\n",
      "Epoch 154/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5902.7839\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5888.6159 - val_loss: 6324.9430\n",
      "Epoch 155/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5895.2715\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5881.1195 - val_loss: 6320.5580\n",
      "Epoch 156/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5887.9173\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5873.7879 - val_loss: 6314.7618\n",
      "Epoch 157/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5880.7901\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5866.6767 - val_loss: 6309.0990\n",
      "Epoch 158/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5873.3035\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5859.2092 - val_loss: 6304.6242\n",
      "Epoch 159/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5866.2707\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5852.1983 - val_loss: 6298.3875\n",
      "Epoch 160/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5859.2247\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5845.1712 - val_loss: 6292.7563\n",
      "Epoch 161/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5851.7133\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5837.6822 - val_loss: 6288.2190\n",
      "Epoch 162/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5844.5461\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5830.5330 - val_loss: 6282.7375\n",
      "Epoch 163/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5837.4762\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5823.4825 - val_loss: 6278.4390\n",
      "Epoch 164/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5830.4346\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 5816.4573 - val_loss: 6273.1188\n",
      "Epoch 165/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5823.4021\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 9s - loss: 5809.4502 - val_loss: 6267.2039\n",
      "Epoch 166/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5816.3372\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5802.4035 - val_loss: 6262.1389\n",
      "Epoch 167/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5809.2756\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 5795.3623 - val_loss: 6256.6481\n",
      "Epoch 168/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5802.2122\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 7s - loss: 5788.3216 - val_loss: 6251.6255\n",
      "Epoch 169/1000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 5795.1498\n",
      "\n",
      "RMSLE error: nan\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 6s - loss: 5781.2800 - val_loss: 6246.6201\n",
      "Epoch 170/1000\n",
      "4352/7452 [================>.............] - ETA: 2s - loss: 3542.4647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception KeyboardInterrupt in 'zmq.backend.cython.message.Frame.__dealloc__' ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-237060031fc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                shuffle=False, class_weight=None, sample_weight=None)\n\u001b[0m",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    789\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rms = ReportRmsleError(X_valid,Y_valid)\n",
    "bike_model.fit(X_train, Y_train,\n",
    "               validation_data=[X_valid,Y_valid], \n",
    "               batch_size=128, nb_epoch=1000, verbose=1, \n",
    "               callbacks=[rms],\n",
    "               shuffle=False, class_weight=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train,Y_train) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"train_binned.pkl\"))\n",
    "(X_valid,Y_valid) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"valid_binned.pkl\"))\n",
    "(X_test,Y_test) = pickle_in(os.path.join(\"../\",\"datasets\",\"generated_features\",\"test_binned.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7452, 10, 27) (1722, 10, 27)\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_valid = mms.transform(X_valid)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "stp_gen = prep.DataToTimeStamps(stamp_size=10,dim_out=3)\n",
    "X_train = stp_gen.fit_transform(X_train)\n",
    "X_valid = stp_gen.fit_transform(X_valid)\n",
    "X_test = stp_gen.fit_transform(X_test)\n",
    "\n",
    "Y_train = Y_train.apply(log_pandas).values.ravel()\n",
    "Y_valid = Y_valid.apply(log_pandas).values.ravel()\n",
    "# Y_train = Y_train.values.ravel()\n",
    "# Y_valid = Y_valid.values.ravel()\n",
    "\n",
    "print X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l2_reg = 0.0000000000001\n",
    "l2_reg_dense = 0.0000000000001\n",
    "\n",
    "bike_lstm_model = Sequential()\n",
    "bike_lstm_model.add(LSTM(10, input_dim=27))\n",
    "bike_lstm_model.add(Dense(256))\n",
    "bike_lstm_model.add(Dense(1))\n",
    "\n",
    "bike_lstm_model.compile(loss =\"mse\",\n",
    "                  optimizer = Adagrad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7452 samples, validate on 1722 samples\n",
      "Epoch 1/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 2.0649\n",
      "\n",
      "RMSLE error: 1.80490051972\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 2.0622 - val_loss: 2.4989\n",
      "Epoch 2/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 1.4619\n",
      "\n",
      "RMSLE error: 1.76170784402\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 1.4606 - val_loss: 1.9262\n",
      "Epoch 3/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 1.2458\n",
      "\n",
      "RMSLE error: 1.75631323055\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 1.2447 - val_loss: 1.5268\n",
      "Epoch 4/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 1.0424\n",
      "\n",
      "RMSLE error: 1.7671939296\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 1.0415 - val_loss: 1.2049\n",
      "Epoch 5/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.8669\n",
      "\n",
      "RMSLE error: 1.79317765146\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.8661 - val_loss: 0.9535\n",
      "Epoch 6/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.7341\n",
      "\n",
      "RMSLE error: 1.82671750747\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.7334 - val_loss: 0.7795\n",
      "Epoch 7/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.6448\n",
      "\n",
      "RMSLE error: 1.85385715932\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.6441 - val_loss: 0.6719\n",
      "Epoch 8/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.5864\n",
      "\n",
      "RMSLE error: 1.87060111084\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.5857 - val_loss: 0.6018\n",
      "Epoch 9/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.5458\n",
      "\n",
      "RMSLE error: 1.88007392395\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.5451 - val_loss: 0.5511\n",
      "Epoch 10/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.5155\n",
      "\n",
      "RMSLE error: 1.88535936548\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.5147 - val_loss: 0.5121\n",
      "Epoch 11/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4917\n",
      "\n",
      "RMSLE error: 1.88847653032\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4909 - val_loss: 0.4814\n",
      "Epoch 12/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4723\n",
      "\n",
      "RMSLE error: 1.89059749634\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4715 - val_loss: 0.4567\n",
      "Epoch 13/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4561\n",
      "\n",
      "RMSLE error: 1.89232184672\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4553 - val_loss: 0.4365\n",
      "Epoch 14/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4423\n",
      "\n",
      "RMSLE error: 1.8938504685\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 0.4415 - val_loss: 0.4199\n",
      "Epoch 15/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4304\n",
      "\n",
      "RMSLE error: 1.89540432049\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4296 - val_loss: 0.4057\n",
      "Epoch 16/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4198\n",
      "\n",
      "RMSLE error: 1.8966599747\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4190 - val_loss: 0.3937\n",
      "Epoch 17/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4105\n",
      "\n",
      "RMSLE error: 1.89781772091\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4097 - val_loss: 0.3832\n",
      "Epoch 18/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.4021\n",
      "\n",
      "RMSLE error: 1.89895445798\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.4013 - val_loss: 0.3739\n",
      "Epoch 19/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3945\n",
      "\n",
      "RMSLE error: 1.90003781308\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.3937 - val_loss: 0.3656\n",
      "Epoch 20/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3876\n",
      "\n",
      "RMSLE error: 1.9010495042\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.3868 - val_loss: 0.3583\n",
      "Epoch 21/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3813\n",
      "\n",
      "RMSLE error: 1.9020538283\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3805 - val_loss: 0.3516\n",
      "Epoch 22/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3755\n",
      "\n",
      "RMSLE error: 1.9031416404\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3747 - val_loss: 0.3456\n",
      "Epoch 23/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3701\n",
      "\n",
      "RMSLE error: 1.9042125855\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3693 - val_loss: 0.3401\n",
      "Epoch 24/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3651\n",
      "\n",
      "RMSLE error: 1.90517634986\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3643 - val_loss: 0.3351\n",
      "Epoch 25/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3604\n",
      "\n",
      "RMSLE error: 1.90614286557\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3597 - val_loss: 0.3305\n",
      "Epoch 26/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3561\n",
      "\n",
      "RMSLE error: 1.90718831752\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3554 - val_loss: 0.3263\n",
      "Epoch 27/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3520\n",
      "\n",
      "RMSLE error: 1.90816069876\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3513 - val_loss: 0.3224\n",
      "Epoch 28/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3482\n",
      "\n",
      "RMSLE error: 1.90911442583\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3474 - val_loss: 0.3188\n",
      "Epoch 29/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3445\n",
      "\n",
      "RMSLE error: 1.91007487137\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3438 - val_loss: 0.3155\n",
      "Epoch 30/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3411\n",
      "\n",
      "RMSLE error: 1.91096591422\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3404 - val_loss: 0.3124\n",
      "Epoch 31/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3379\n",
      "\n",
      "RMSLE error: 1.91186005158\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3372 - val_loss: 0.3095\n",
      "Epoch 32/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3348\n",
      "\n",
      "RMSLE error: 1.91268695332\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3341 - val_loss: 0.3068\n",
      "Epoch 33/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3319\n",
      "\n",
      "RMSLE error: 1.91350944027\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.3312 - val_loss: 0.3042\n",
      "Epoch 34/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3292\n",
      "\n",
      "RMSLE error: 1.91431287546\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3285 - val_loss: 0.3017\n",
      "Epoch 35/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3265\n",
      "\n",
      "RMSLE error: 1.91508347778\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.3259 - val_loss: 0.2994\n",
      "Epoch 36/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3240\n",
      "\n",
      "RMSLE error: 1.91583745176\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3234 - val_loss: 0.2971\n",
      "Epoch 37/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3216\n",
      "\n",
      "RMSLE error: 1.91656389557\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3210 - val_loss: 0.2950\n",
      "Epoch 38/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3193\n",
      "\n",
      "RMSLE error: 1.9172869782\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3187 - val_loss: 0.2929\n",
      "Epoch 39/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3171\n",
      "\n",
      "RMSLE error: 1.91801535147\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3164 - val_loss: 0.2910\n",
      "Epoch 40/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3150\n",
      "\n",
      "RMSLE error: 1.91873807005\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3143 - val_loss: 0.2891\n",
      "Epoch 41/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3129\n",
      "\n",
      "RMSLE error: 1.919415089\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3123 - val_loss: 0.2873\n",
      "Epoch 42/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3110\n",
      "\n",
      "RMSLE error: 1.92007251194\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3103 - val_loss: 0.2856\n",
      "Epoch 43/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3091\n",
      "\n",
      "RMSLE error: 1.92072249123\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3084 - val_loss: 0.2839\n",
      "Epoch 44/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3072\n",
      "\n",
      "RMSLE error: 1.92137650939\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3066 - val_loss: 0.2823\n",
      "Epoch 45/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3055\n",
      "\n",
      "RMSLE error: 1.92199472139\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3048 - val_loss: 0.2807\n",
      "Epoch 46/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3038\n",
      "\n",
      "RMSLE error: 1.92260932887\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3031 - val_loss: 0.2793\n",
      "Epoch 47/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3021\n",
      "\n",
      "RMSLE error: 1.92320788938\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.3015 - val_loss: 0.2778\n",
      "Epoch 48/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.3005\n",
      "\n",
      "RMSLE error: 1.92378071592\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2999 - val_loss: 0.2764\n",
      "Epoch 49/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2990\n",
      "\n",
      "RMSLE error: 1.92435298685\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2984 - val_loss: 0.2751\n",
      "Epoch 50/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2975\n",
      "\n",
      "RMSLE error: 1.92491002109\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2969 - val_loss: 0.2738\n",
      "Epoch 51/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2961\n",
      "\n",
      "RMSLE error: 1.92545429344\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2954 - val_loss: 0.2725\n",
      "Epoch 52/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2946\n",
      "\n",
      "RMSLE error: 1.92597796088\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2940 - val_loss: 0.2713\n",
      "Epoch 53/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2933\n",
      "\n",
      "RMSLE error: 1.92650916864\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2927 - val_loss: 0.2701\n",
      "Epoch 54/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2919\n",
      "\n",
      "RMSLE error: 1.92701731518\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2913 - val_loss: 0.2689\n",
      "Epoch 55/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2906\n",
      "\n",
      "RMSLE error: 1.92751267989\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2900 - val_loss: 0.2678\n",
      "Epoch 56/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2894\n",
      "\n",
      "RMSLE error: 1.92799755188\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2888 - val_loss: 0.2667\n",
      "Epoch 57/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2881\n",
      "\n",
      "RMSLE error: 1.92848507094\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2875 - val_loss: 0.2656\n",
      "Epoch 58/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2869\n",
      "\n",
      "RMSLE error: 1.92894911515\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2863 - val_loss: 0.2646\n",
      "Epoch 59/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2858\n",
      "\n",
      "RMSLE error: 1.92941585195\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2851 - val_loss: 0.2635\n",
      "Epoch 60/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2846\n",
      "\n",
      "RMSLE error: 1.92987885033\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2840 - val_loss: 0.2626\n",
      "Epoch 61/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2835\n",
      "\n",
      "RMSLE error: 1.93031455253\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2829 - val_loss: 0.2616\n",
      "Epoch 62/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2824\n",
      "\n",
      "RMSLE error: 1.93074341474\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2817 - val_loss: 0.2606\n",
      "Epoch 63/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2813\n",
      "\n",
      "RMSLE error: 1.93117663536\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2807 - val_loss: 0.2597\n",
      "Epoch 64/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2802\n",
      "\n",
      "RMSLE error: 1.93160109195\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2796 - val_loss: 0.2588\n",
      "Epoch 65/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2792\n",
      "\n",
      "RMSLE error: 1.9320185524\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2785 - val_loss: 0.2578\n",
      "Epoch 66/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2781\n",
      "\n",
      "RMSLE error: 1.93243077486\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2775 - val_loss: 0.2570\n",
      "Epoch 67/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2771\n",
      "\n",
      "RMSLE error: 1.93284598921\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2765 - val_loss: 0.2561\n",
      "Epoch 68/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2761\n",
      "\n",
      "RMSLE error: 1.93326254857\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2755 - val_loss: 0.2552\n",
      "Epoch 69/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2751\n",
      "\n",
      "RMSLE error: 1.93367006911\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2745 - val_loss: 0.2544\n",
      "Epoch 70/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2742\n",
      "\n",
      "RMSLE error: 1.93406285091\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2736 - val_loss: 0.2536\n",
      "Epoch 71/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2732\n",
      "\n",
      "RMSLE error: 1.93445822993\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2726 - val_loss: 0.2527\n",
      "Epoch 72/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2723\n",
      "\n",
      "RMSLE error: 1.93485741045\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2717 - val_loss: 0.2519\n",
      "Epoch 73/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2714\n",
      "\n",
      "RMSLE error: 1.93524411697\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2708 - val_loss: 0.2511\n",
      "Epoch 74/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2705\n",
      "\n",
      "RMSLE error: 1.93562242979\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2699 - val_loss: 0.2504\n",
      "Epoch 75/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2696\n",
      "\n",
      "RMSLE error: 1.93598884845\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2690 - val_loss: 0.2496\n",
      "Epoch 76/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2687\n",
      "\n",
      "RMSLE error: 1.93637016298\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2681 - val_loss: 0.2489\n",
      "Epoch 77/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2678\n",
      "\n",
      "RMSLE error: 1.93673016064\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2672 - val_loss: 0.2481\n",
      "Epoch 78/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2669\n",
      "\n",
      "RMSLE error: 1.93707767912\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2663 - val_loss: 0.2474\n",
      "Epoch 79/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2661\n",
      "\n",
      "RMSLE error: 1.93742591853\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2655 - val_loss: 0.2467\n",
      "Epoch 80/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2652\n",
      "\n",
      "RMSLE error: 1.93778216368\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2646 - val_loss: 0.2459\n",
      "Epoch 81/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2644\n",
      "\n",
      "RMSLE error: 1.93812965322\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2638 - val_loss: 0.2452\n",
      "Epoch 82/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2636\n",
      "\n",
      "RMSLE error: 1.93847743317\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2630 - val_loss: 0.2445\n",
      "Epoch 83/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2628\n",
      "\n",
      "RMSLE error: 1.93882361277\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2622 - val_loss: 0.2439\n",
      "Epoch 84/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2620\n",
      "\n",
      "RMSLE error: 1.93916275033\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2614 - val_loss: 0.2432\n",
      "Epoch 85/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2612\n",
      "\n",
      "RMSLE error: 1.9394967911\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 5s - loss: 0.2606 - val_loss: 0.2425\n",
      "Epoch 86/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2604\n",
      "\n",
      "RMSLE error: 1.93982889829\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2598 - val_loss: 0.2419\n",
      "Epoch 87/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2596\n",
      "\n",
      "RMSLE error: 1.94017322261\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.2590 - val_loss: 0.2412\n",
      "Epoch 88/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2588\n",
      "\n",
      "RMSLE error: 1.94051023277\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2582 - val_loss: 0.2406\n",
      "Epoch 89/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2581\n",
      "\n",
      "RMSLE error: 1.9408456233\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 4s - loss: 0.2575 - val_loss: 0.2400\n",
      "Epoch 90/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2573\n",
      "\n",
      "RMSLE error: 1.94117760008\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2567 - val_loss: 0.2393\n",
      "Epoch 91/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2566\n",
      "\n",
      "RMSLE error: 1.9414857804\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2560 - val_loss: 0.2387\n",
      "Epoch 92/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2558\n",
      "\n",
      "RMSLE error: 1.94179955123\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2552 - val_loss: 0.2381\n",
      "Epoch 93/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2551\n",
      "\n",
      "RMSLE error: 1.94210652977\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2545 - val_loss: 0.2375\n",
      "Epoch 94/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2544\n",
      "\n",
      "RMSLE error: 1.94241861058\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2538 - val_loss: 0.2369\n",
      "Epoch 95/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2536\n",
      "\n",
      "RMSLE error: 1.94272298919\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2531 - val_loss: 0.2364\n",
      "Epoch 96/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2529\n",
      "\n",
      "RMSLE error: 1.94301226101\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2524 - val_loss: 0.2358\n",
      "Epoch 97/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2522\n",
      "\n",
      "RMSLE error: 1.94330890098\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2516 - val_loss: 0.2352\n",
      "Epoch 98/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2515\n",
      "\n",
      "RMSLE error: 1.94360438538\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2509 - val_loss: 0.2347\n",
      "Epoch 99/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2508\n",
      "\n",
      "RMSLE error: 1.94389140778\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2502 - val_loss: 0.2341\n",
      "Epoch 100/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2501\n",
      "\n",
      "RMSLE error: 1.94418230248\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2496 - val_loss: 0.2335\n",
      "Epoch 101/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2494\n",
      "\n",
      "RMSLE error: 1.94446918748\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2489 - val_loss: 0.2330\n",
      "Epoch 102/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2488\n",
      "\n",
      "RMSLE error: 1.94474820136\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2482 - val_loss: 0.2325\n",
      "Epoch 103/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2481\n",
      "\n",
      "RMSLE error: 1.94502423935\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2475 - val_loss: 0.2319\n",
      "Epoch 104/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2474\n",
      "\n",
      "RMSLE error: 1.94529383248\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2469 - val_loss: 0.2314\n",
      "Epoch 105/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2468\n",
      "\n",
      "RMSLE error: 1.94555734346\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2462 - val_loss: 0.2309\n",
      "Epoch 106/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2461\n",
      "\n",
      "RMSLE error: 1.94582097089\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2455 - val_loss: 0.2304\n",
      "Epoch 107/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2454\n",
      "\n",
      "RMSLE error: 1.94609248685\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2449 - val_loss: 0.2299\n",
      "Epoch 108/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2448\n",
      "\n",
      "RMSLE error: 1.94635264218\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2442 - val_loss: 0.2294\n",
      "Epoch 109/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2442\n",
      "\n",
      "RMSLE error: 1.94660011821\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2436 - val_loss: 0.2289\n",
      "Epoch 110/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2435\n",
      "\n",
      "RMSLE error: 1.94685113793\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2430 - val_loss: 0.2284\n",
      "Epoch 111/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2429\n",
      "\n",
      "RMSLE error: 1.94710120972\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2423 - val_loss: 0.2279\n",
      "Epoch 112/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2422\n",
      "\n",
      "RMSLE error: 1.94734682167\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2417 - val_loss: 0.2274\n",
      "Epoch 113/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2416\n",
      "\n",
      "RMSLE error: 1.94759247759\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2411 - val_loss: 0.2269\n",
      "Epoch 114/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2410\n",
      "\n",
      "RMSLE error: 1.94783812178\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2404 - val_loss: 0.2264\n",
      "Epoch 115/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2404\n",
      "\n",
      "RMSLE error: 1.94807752561\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2398 - val_loss: 0.2260\n",
      "Epoch 116/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2398\n",
      "\n",
      "RMSLE error: 1.94831394945\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2392 - val_loss: 0.2255\n",
      "Epoch 117/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2391\n",
      "\n",
      "RMSLE error: 1.94854981525\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 3s - loss: 0.2386 - val_loss: 0.2250\n",
      "Epoch 118/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2385\n",
      "\n",
      "RMSLE error: 1.94877368815\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2380 - val_loss: 0.2245\n",
      "Epoch 119/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2379\n",
      "\n",
      "RMSLE error: 1.94899178798\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2374 - val_loss: 0.2241\n",
      "Epoch 120/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2373\n",
      "\n",
      "RMSLE error: 1.94922377051\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2368 - val_loss: 0.2236\n",
      "Epoch 121/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2367\n",
      "\n",
      "RMSLE error: 1.94943857407\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2362 - val_loss: 0.2232\n",
      "Epoch 122/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2361\n",
      "\n",
      "RMSLE error: 1.94967320244\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2356 - val_loss: 0.2227\n",
      "Epoch 123/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2355\n",
      "\n",
      "RMSLE error: 1.94989330721\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2350 - val_loss: 0.2223\n",
      "Epoch 124/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2350\n",
      "\n",
      "RMSLE error: 1.95011469835\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2344 - val_loss: 0.2218\n",
      "Epoch 125/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2344\n",
      "\n",
      "RMSLE error: 1.95033386792\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2338 - val_loss: 0.2214\n",
      "Epoch 126/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2338\n",
      "\n",
      "RMSLE error: 1.95054640593\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2332 - val_loss: 0.2209\n",
      "Epoch 127/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2332\n",
      "\n",
      "RMSLE error: 1.95076023329\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2327 - val_loss: 0.2205\n",
      "Epoch 128/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2326\n",
      "\n",
      "RMSLE error: 1.95097006565\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2321 - val_loss: 0.2200\n",
      "Epoch 129/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2320\n",
      "\n",
      "RMSLE error: 1.95118247793\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2315 - val_loss: 0.2196\n",
      "Epoch 130/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2315\n",
      "\n",
      "RMSLE error: 1.95140138633\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2309 - val_loss: 0.2192\n",
      "Epoch 131/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2309\n",
      "\n",
      "RMSLE error: 1.95160896311\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2304 - val_loss: 0.2188\n",
      "Epoch 132/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2303\n",
      "\n",
      "RMSLE error: 1.95181127183\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2298 - val_loss: 0.2183\n",
      "Epoch 133/10000\n",
      "7424/7452 [============================>.] - ETA: 0s - loss: 0.2297\n",
      "\n",
      "RMSLE error: 1.9520127617\n",
      "\n",
      "\n",
      "7452/7452 [==============================] - 2s - loss: 0.2292 - val_loss: 0.2179\n",
      "Epoch 134/10000\n",
      "7168/7452 [===========================>..] - ETA: 0s - loss: 0.2306Traceback (most recent call last):\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 970, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 233, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 267, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/inspect.py\", line 500, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/posixpath.py\", line 375, in realpath\n",
      "    path, ok = _joinrealpath('', filename, {})\n",
      "  File \"/home/jakubczakon/anaconda2/lib/python2.7/posixpath.py\", line 399, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[0;32m   1878\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1879\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1880\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1242\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1148\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1150\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m             )\n\u001b[0;32m   1152\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1002\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecords\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jakubczakon/anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mformat_records\u001b[1;34m(self, records)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[0mabspath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m             \u001b[1;31m#print '*** record:',file,lnum,func,lines,index  # dbg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "rms = ReportRmsleError(X_valid,Y_valid)\n",
    "bike_lstm_model.fit(X_train, Y_train,\n",
    "               validation_data=[X_valid,Y_valid], \n",
    "               batch_size=128, nb_epoch=10000, verbose=1, \n",
    "               callbacks=[rms],\n",
    "               shuffle=False, class_weight=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
